{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Documentation for pynxtools-em","text":"<p>pynxtools-em is a free and open-source data software for creating standardized semantic serializations of electron microscopy data and metadata for research data management using NeXus, implemented with the goal to make scientific research data FAIR (findable, accessible, interoperable, and reusable).</p> <p>pynxtools-em, which is a plugin for pynxtools, provides a tool for reading data and metadata from various proprietary and open data formats from technology partners and the wider electron microscopy community and standardizing it such that it is compliant with the NeXus application definition <code>NXem</code>.</p> <p>pynxtools-em is developed both as a standalone reader and as a tool within NOMAD, which is the open-source research data management platform for materials science we are developing with FAIRmat.</p> <p>pynxtools-em solves the challenge of using heterogeneous and semantically ambiguous serialization formats which is common in electron microscopy. In addition, it provides an interface for writing readers for different file formats to be mapped to NeXus.</p> <p>pynxtools-em is useful for scientists from the electron microscopy community, for technology partners, software developers, and data providers who search for ways to make their data more completely aligned with the aims of the FAIR principles. Specifically the tool is useful for research groups who wish to organize their research data based on an interoperable standard.</p>  Contact  <p>For questions or suggestions:</p> <ul> <li>Open an issue on the <code>pynxtools-em</code> GitHub</li> <li>Join our Discord channel</li> <li>Get in contact with our lead developers.</li> </ul> Project and community <ul> <li>NOMAD code guidelines</li> </ul> <p>The work is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 460197019 (FAIRmat).</p>"},{"location":"index.html#tutorial","title":"Tutorial","text":"<p>A series of tutorials giving you an overview on how to store or convert your EM data to NeXus compliant files.</p> <ul> <li>Installation guide</li> <li>Standalone usage</li> <li>Development guide</li> </ul>"},{"location":"index.html#how-to-guides","title":"How-to guides","text":"<p>How-to guides provide step-by-step instructions for a wide range of tasks, with the overarching topics:</p> <ul> <li>Kikuchi diffraction</li> </ul>"},{"location":"index.html#learn","title":"Learn","text":"<p>The explanation section provides background knowledge on the implementation design.</p> <ul> <li>Implementation design</li> </ul>"},{"location":"index.html#reference","title":"Reference","text":"<p>Here you can learn which specific pieces of information and concepts pynxtools-em currently supports for the respective file formats of technology partners of the electron microscopy community.</p> <ul> <li> <p>How to map pieces of information to NeXus</p> </li> <li> <p>Conventions collected with a text file or ELN</p> </li> <li> <p>Metadata collected with an ELN and RDM-specific configurations</p> </li> <li> <p>AXON Protochips Portable Network Graphics PNG</p> </li> <li>FEI Legacy Tagged Image File Format TIFF</li> <li>EDAX APEX</li> <li>Gatan DigitalMicrograph DM3/DM4</li> <li>Hitachi Tagged Image File Format TIFF</li> <li>JEOL Tagged Image File Format TIFF</li> <li>Nion Co. projects with NDATA and HDF5 files</li> <li>Point Electronic DISS Tagged Image File Format TIFF</li> <li>TESCAN Tagged Image File Format TIFF</li> <li>ThermoFisher Tagged Image File Format TIFF</li> <li>ThermoFisher Velox EMD</li> <li>Zeiss Tagged Image File Format TIFF</li> <li>EBSD-centric content for the parsing route via MTex</li> <li>EBSD-centric content for the parsing route via pyxem</li> </ul>"},{"location":"contact.html","title":"Get in contact","text":"<p>NOMAD, <code>pynxtools</code> and <code>pynxtools-em</code> are open source project that warmly welcome community projects, contributions, suggestions, bug fixes, and constructive feedback. <code>pynxtools</code> is build mainly within FAIRmat Area B - Experiment.</p> <p>You can reach us by different channels. You can send an email directly to one of the main contributors:</p> Name E-mail Github profiles fairmat@physik.hu-berlin.de <ul> <li>Open an issue on GitHub</li> <li>Join the NOMAD discord channel and ask us there directly.</li> </ul>"},{"location":"explanation/emapp.html","title":"NOMAD App","text":"<p>pynxtools-em provides the NOMAD research data management system with an optional NOMAD custom app that implements an example how to offer domain-specific search capabilities on electron microscopy data in NOMAD.</p>"},{"location":"explanation/implementation.html","title":"Implementation design","text":"<p>Pynxtools-em addresses current challenges with the representation of information in the field of electron microscopy through leading by examples. Specifically, the tool implements functionalities for ontology matching of instance data from proprietary representations to an open format and standard - NeXus and the NXem application definitions and respective concepts. The examples which pynxtools-em currently supports are for sure a compromise. This is clear, if we consider how large the potential space of all possible naming conventions and combinations of pieces of information in the electron microscopy community is that one could and in which formatting one could share knowledge of this field. Existent differences (in terms of precision, language, encoding style, and constraints) how technically information can be serialized make this combinatorial space of possible representations even larger.</p> <p>The following design patterns guide our implementation:</p> <ul> <li>We do not consider that our work is complete from the perspective of the often short-term-project-driven mindset but that standardization is a community effort.</li> <li>We consider ontology matching a team effort that can only be achieved with technology partners and scientists working together.</li> <li>We acknowledge the efforts and key contributions that went into the development of file format reading libraries and data analysis libraries of the electron microscopy community. We had to start somewhere and we did so with tools from the hyperspy ecosystem rosettasciio, pyxem, and kikuchipy. We would be happy to work together with representatives from the many other great software packages within the community. We have realized that being able to read as well as to write instance data in specific file formats of the community is a necessary but not a sufficient enough achievement went electron microscopy data should really at some point fulfill the FAIR principles. Until the community will have arrived to the point that for every such file format there is also an exchange of the specification of the format. It is this semantic documentation which is often missing still in the field of electron microscopy because of which still many formats and hence activities rely on having to reverse engineer reading capabilities instead of being able to take advantage already from having semantically interoperable machine-actionable electron microscopy information storage. </li> <li>Our work is open to suggestions by all members of the electron microscopy community.</li> <li>We have chosen specific tangible examples of (meta)data semantic mapping for specific methods that are used in electron microscopy. These examples have been implemented to explore along two routes:</li> <li>There are examples of parsing capabilities (for TIFF and PNG) which address rather technical aspects (e.g. how to read from such files and pick technology-partner-specific formatting of instance data). These examples must not be understood as that they implemented such that they provide parsing capabilities for all arbitrary examples with that specific mime type. There are two practical reasons for this: Firstly, limited manpower to implement all this. Secondly, limited availability of reliable documentation that defines the semantic content that specific file formats from technology partners encode. Both challenges can be solved: The first one with support from the community. The second one with support from technology partners.</li> <li>There are examples of parsing examples for a specific method - for now Electron Backscatter Diffraction (EBSD) and Transmission Kikuchi Diffraction (TKD) - for which we have explored how a large number of different formats can be parsed and how that parsing can be made more general and robust than to just support one prototypic example as we see it happening currently in the field of research data management. We are aware that we do not parse everything but rather an exemplar subset that suffices to offer a comprehensive example of how key information such as orientation maps, region-of-interest analyzed, or descriptors derived from these analyses, can be harmonized. The reason for this selection has been motivated by the fact to show that there is at all a benefit of normalizing comprehensive and technically deep representations of electron microscopy data.</li> </ul>"},{"location":"explanation/implementation.html#purpose-and-aim-of-pynxtools-em","title":"Purpose and aim of pynxtools-em","text":"<p>We would like to provide context to the purpose and aim of pynxtools-em. The software implements a suggestion how diverse (meta)data from the research field of electron microscopy can be parsed and normalized to enable users a precise comparison of information and knowledge. This means instance data need to be powered by semantics. The software pynxtools-em maps instance data from different formatting and concepts onto a proposal for a common information exchange and representation semantic representation via NeXus. The software achieves this through a two-stepped process of parsing. Firstly, via reading data from technology partner or specific serialization and formatting. Secondly, via applying transformations (if required) to map on NeXus. One of the key motivations for the development of pynxtools and its plugins was to explore and show how pieces of information can be harmonized and matched to enable the development of data-centric software tools and services in research data management systems (RDMS). The key reason to place such code into plugins rather than into the RDM source code itself is to promote reusability, to offer users a stronger modularizability and possibilities for tailoring of the RDM. Avoiding a duplication of development efforts that typically come with having to maintain many instead of a few codes, having many file formats instead of a few ones which are defined based on semantics is an effective strategy to focus when developer resources are finite like in electron microscopy.</p>"},{"location":"explanation/implementation.html#software-tools-in-electron-microscopy-a-mixture-of-proprietary-and-open-source-solutions","title":"Software tools in electron microscopy - a mixture of proprietary and open-source solutions","text":"<p>Typically, users work with proprietary software from technology partners and use custom-written software (many of which nowadays have an open-source license) frequently. Proprietary software offers frequently lower usage barriers for end users surplus offer specifically tailored access to and capabilities of storing instrument-specific (meta)data via a user interface that is optimized for efficient usage of the microscope. As a burden, proprietary software tools often write (not exclusively though) to proprietary serialization formats (file or database entries). These formats encode semantic concepts but that knowledge is proprietary. The key challenge is that the content and meaning of these concepts is very often not documented publicly. Therefore, there is a frequent necessity for having to convert between formats. When such conversions are performed ad hoc, substantial contextual information can get lost or become disconnected which makes tracking of workflows in electron microscopy difficult.</p> <p>Several proprietary software tools implement the execution of script-based analyses. This scripting is also a key signature of the many software tools with an open-source development mindset and license. These offer an increasingly competitive alternative to proprietary software tools in electron microscopy. The combination of open source code, customizability, and the rooting (or often only reason for their existence) in exploring cutting-edge prototyping of algorithms and ideas by the scientific community, has made script-based software nowadays a reality in many electron microscopy labs - especially in the Python world. This justifies thoughts on how using such software aligns with the aims of the FAIR principles of data stewardship.</p> <p>Here, script-based analyses can be considered a benefit and a burden when it comes to FAIR principles: The flexibility of being able to script ones analysis is a clear benefit. However, it is a burden at the same time because of the current state of how such workflows are typically documented. That is by users sharing such scripts alongside processed data in some processed state surplus the (close to) or final figures that were generated with the publication. Hence, it is often just assumed that these scripts not only work for different versions of the execution environment (i.e. different Matlab version) but also that users can obtain the same results - provided they run the scripts again using the data if these are provided.</p> <p>The truth though is that this often leaves room for substantial interpretation and ambiguity. When there is neither a community agreed-upon standard of how to exchange information nor a thorough documentation of the execution environment, and possibly a lack of how the serialized artifacts (files, database entries) were processed through this workflow. The practical challenge is not that no output files to such script execution are shared but that these are shared using a large variety of formats many of which using ad hoc data schemas. This is a substantial burden from the perspective of ontology matching because pieces of information are encoded and named differently although they (to human experts) represent instances of similar, equivalent, or even exactly the same concepts. So far it demands the capabilities of members and often domain experts within the electron microscopy community to assure that data can safely be compared from a scientific point of view. It is this not yet fully implemented semantic mapping which technically limits interoperable knowledge exchange in electron microscopy rather than being able to read or write a specific file format.</p>"},{"location":"explanation/learn.html","title":"Scope and idea","text":"<p>pynxtools-em offers the electron microscopy community a set of diverse examples how a parser can be implemented to provide for a diverse and wide coverage of the (meta)data from the research field of electron microscopy. We would like to encourage the community to share example files with us. These can be small and come from diverse use cases.</p>"},{"location":"explanation/learn.html#workflow","title":"Workflow","text":"<p>The following diagram shows how <code>pynxtools-em</code> processes data and metadata and interacts as a plugin with the core routines of <code>pynxtools</code>.</p> <p></p>"},{"location":"how-tos/examples.html","title":"Different usage examples","text":"<p>pynxtools-em and exemplar customizations of the NOMAD research data management system provide examples how different types of electron microscopy data can be standardized and worked with.</p> <p>The examples cover different techniques and have different technical depth and coverage:</p> <ul> <li>Electron backscatter diffraction, EBSD, Kikuchi diffraction in the scanning electron (SEM) or transmission electron microscope (TEM). This example offers both a broad in format coverage and technical deep standardization of EBSD datasets that has been tested with thousands of datasets from research groups across the globe.</li> </ul> <p>This is something that is good to note.</p> <ul> <li>Energy-dispersive X-ray spectroscopy (EDS) - this example offers a broad in format generic implementation for visualizing EDS mappings.</li> <li>Different imaging modes - this example offers a broad in format generic implementation for visualizing electron microscopy images that have been taken with either SEM or TEM instruments using different imaging modes.</li> </ul>"},{"location":"how-tos/howto.html","title":"How-to","text":""},{"location":"how-tos/kikuchi.html","title":"Kikuchi diffraction","text":"<p>The following diagram shows a comprehensive example how diverse datasets from Kikuchi diffraction can be normalized using different tools from the scientific community and <code>pynxtools-em</code> as the glue tool to create a NeXus/HDF5 artifact that can be useful for creating supplementary material in publications or research data management systems or electronic laboratory notebooks.</p> <p></p> <ul> <li>Further details to the parsing route via MTex</li> <li>Further details to the parsing route via pyxem</li> <li>Further details to the NXem_ebsd base class</li> <li>Further details to  the NXem application definition</li> </ul>"},{"location":"how-tos/mtex.html","title":"Kikuchi diffraction via MTex","text":"<p>MTex is a software for texture analysis written in MATLAB. The software is one of the key tools of materials engineers and geologists to perform computations in orientation space to segment a characterized portion of material into a representation of its microstructure. The software offers the largest and most mature solution for analyzing and plotting texture analyses whereby research questions about texture quantification and visualization using pole figures, orientation distribution functions, inverse pole figures, and grain-boundary-network characterization is achieved. Thanks to its support of all symmetry classes, the tool has not only found wide acceptance within the field of materials engineering but also within the geoscience communities.</p> <p>As a result, this MTex-based parsing of certain Kikuchi diffraction relevant content equips the pynxtools-em parser and normalizer currently with functionalities to read the following content and map on respective NeXus concepts that are defined in the NXem application definition and the NXem_ebsd base class:</p> Orientation, phase NeXus/HDF5 Oxford Instruments ANG HKL Channel5 CPR/CRC OSC CTF"},{"location":"how-tos/pyxem.html","title":"Kikuchi diffraction via pyxem","text":"<p>In recent years shortcomings of classical text-based file formats for serializing Kikuchi diffraction data have been realized and lead to a replacement of these formats with proprietary and open-source alternatives that use binary containers like Hierarchical Data Format (HDF)5. At the point when we started the implementation of the Kikuchi diffraction examples for the FAIRmat project, several of these formats were not yet supported by MTex. In parallel, we acknowledge the complementary analyses capabilities for Python users that the work of the pyxem and hyperspy developers providers for the electron microscopy community. Therefore, we decided that as a technical implementation example we will implement the first version such that it uses, apart from MTex, the I/O and orientation math capabilities of these Python libraries.</p> <p>As a result, this pyxem-based parsing of HDF5-serialized Kikuchi diffraction content equips the pynxtools-em parser and normalizer currently with functionalities to read the following content and map on respective NeXus concepts that are defined in the NXem application definition and the NXem_ebsd base class:</p> Orientation, phase NeXus/HDF5 Oxford Instruments H5OINA HDF5 Bruker Esprit HDF5 H5EBSD-based community format ThermoFisher Velox EDAX APEX DREAM.3D v6 () EMsoft HDF5 ()"},{"location":"reference/contextualization.html","title":"How to map pieces of information to NeXus","text":"<p>Conceptually, mapping between representations of concepts and instance data is a key tasks in information science. The plugin pynxtools-em implements this specifically for serialization formats used within the research field of electron microscopy. The plugin offloads this code from other software to avoid that every user and software developer have to make individual changes in their own tools.</p> <p>Technically, instance data representing concepts within the realm of one ontology or file format are considered the source (<code>src</code>). These instance data are mapped on instance data representing a concept in NeXus as the target (<code>trg</code>). A transformation can be as simple as that an instance <code>src</code> has an elementary data type (e.g. a string or single-precision floating point value) that is copied into an instance <code>trg</code> of the same data type. Often though, such a mapping demands further normalization. One example is when <code>src</code> represents say a quantity such as a tilt angle with a value in unit radiants but <code>trg</code> requires that this value should be stored in unit degrees. In this case, the transformation is composed of a read of the value from <code>src</code>, a multiplication to convert from radiants to degrees, and the return of the value as <code>trg</code>.</p> <p>Such transformations are configured via the respective files in the config directory of pynxtools-em. Upon parsing, it is this set of functions in mapping_functor.py which implement the actual transformations by reading the configuration and returning the properly formatted and transformed target to fill the <code>template</code> dictionary variable.</p> <p>The name functor is used because mapping may demand (as above-mentioned) more than copying the instance data. It is this template variable from which core functions like convert.py of the pynxtools library then write the actual NeXus/HDF5 file. The latter tool is also referred to as the dataconverter of pynxtools.</p> <p>A more detailed definition of the mapping approach is documented here</p>"},{"location":"reference/conventions.html","title":"Conventions collected with a text file or ELN","text":""},{"location":"reference/eln_and_cfg.html","title":"Metadata collected with an ELN and RDM-specific configurations","text":""},{"location":"reference/hfive_apex.html","title":"EDAX APEX","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> <p>This is currently documented via the pynxtools-em source code only.</p>"},{"location":"reference/mapping.html","title":"Mapping","text":""},{"location":"reference/mapping.html#contextualization","title":"Contextualization","text":"<p>If data models of technology partners would be communicated using tools and methods from the field of semantic technology, there would be less of a necessity to copy or reformat specific information into files as one could write inference and information/fact/knowledge retrieval algorithm(s) whereby a specific piece of information that is related to an experiment or simulation is read directly from the respective file of the technology partner and converted semantically into the representation that is required on the target side.</p> <p>The reason why currently this does not work convincingly in cases for many open-source research data management software is the strong heterogeneity of how granularized pieces of information are expected surplus the observation that contextualization and documentation, specifically rich and strongly expressive semantic documentation or contextualization, is underdeveloped.</p>"},{"location":"reference/mapping.html#technical-details-about-the-mapping-approach","title":"Technical details about the mapping approach","text":"<p>Mapping information from one serialization format onto another can face various cases of information content, representation, and formatting mismatch as the data models can differ. Assume that we wish to map instance data for concepts on the src side, e.g. content stored from files collected during an measurement, onto instance data for concepts of a different data model on the trg side. Several cases of mismatch can occur:</p> <ol> <li>Mismatch in symbols (aka concept names) used for identifying concepts An example: high_voltage is expected by trg but HV is used as a symbol by src.</li> <li>Mismatch in units An example: trg expects voltage quantities with unit V but src provides unit kV. Another example: trg expects angle as radian but src provides deg.</li> <li>Mismatch in data types An example: np.float64 is expected by trg but single precision float is used by src. Another example: 1 as an int is expected by trg but that number has been serialized as a string \"1\". One more example: trg expects voltage as V but on src tech partners agreed to use SI unit but do not write these unit explicitly.</li> <li>Mismatch in the granularization of information or different standards used for representing information An example: trg expects ISO8601 with local time zone offset to UTC but src provides date, time, and timezone as individual strings. Another example: trg expects UNIX timestamp but src provides MS-DOS timestamp.</li> <li>Mismatch in dimensions An example: trg requests an (&gt;1,) array but src only provides a scalar</li> </ol> <p>Configurations are the solutions which guide the parser how to map instance data for each concept. Often the mismatch cannot be resolved because the trg and src have not exchanged precisely defined versions of their data models. In this case, one often uses assumptions.</p> <p>Configurations implement these assumptions and mapping decisions outside the actual source code to offer a single place where preferentially such mismatches should be resolved. This enables users to often avoid having to take a look into the backend code surplus this solutions avoids that the mapping of potentially many individual concepts becomes too strongly hard-coded and long mapping pathes need be repeated which would create code bloat.</p> <p>Configurations should group mapping rules to reduce the overall size of the mapping dictionaries. Configurations are stored as Python dictionaries with specific formatting. Configurations use abbreviations wherever possible. All combined, this yields compact descriptions that are hopefully easier to read and having fewer places where changes need to be implemented when mapping paths change as the data models evolve.</p> <p>Mismatch cases 1, 2, 3, 4 are dealt with. Mismatch case 5 is currently ignored. Instead, instance data from src are copied to trg if no mismatch 1 -4 is observed. This may cause though that the resulting collection of instance data on the trg side does not end up fully compliant with an application definition. However, this is not a problem because verification of the instance data takes place during consumption of the serialized NeXus artifact/file.</p> <p>Attention</p> <p>Remaining paragraphs sketch a draft of the documentation for the technical details of the mapping.</p> <p>The following example shows one typical such dictionary.</p> <pre><code>AXON_STATIC_STAGE_NX: Dict[str, Any] = {\n    \"prefix_trg\": \"/ENTRY[entry*]/measurement/instrument/stageID[stage]\",\n    \"prefix_src\": \"MicroscopeControlImageMetadata.ActivePositionerSettings.PositionerSettings.[*].Stage.\",\n    \"use\": [(\"design\", \"heating_chip\")],\n    \"map\": [(\"alias\", \"Name\")],\n}\n</code></pre> <p>In this example the template path for the tuple in use on the trg side will be f\"{prefix_trg}/{use[0][0]}\" with value use[0][1]. The template path for the tuple in map on the trg side will be f\"{prefix_trg}{map[0][0]}\" with the value that is read from the src side pointed to by keyword f\"{prefix_src}{map[0][1]}\".</p> <p>Problems with the old algorithm can be exemplified with the following example <pre><code>VELOX_DYNAMIC_STAGE_NX: Dict[str, Any] = {\n    \"prefix_trg\": \"/ENTRY[entry*]/measurement/eventID[event*]/instrument/stageID[stage]\",\n    \"use\": [\n        (\"tilt1/@units\", \"rad\"),\n        (\"tilt2/@units\", \"rad\"),\n        (\"position/@units\", \"m\"),\n    ],\n    \"map_to_str\": [(\"design\", \"Stage/HolderType\")],\n    \"map_to_real\": [\n        (\"tilt1\", \"Stage/AlphaTilt\"),\n        (\"tilt2\", \"Stage/BetaTilt\"),\n        (\"position\", [\"Stage/Position/x\", \"Stage/Position/y\", \"Stage/Position/z\"]),\n    ],\n}\n</code></pre></p> <p>Keywords use and map were looped over. Therefore, template pathes like tilt1/@units were set independently whether the corresponding value tilt1 was found. The new approach solves this and makes the dictionary more compact: <pre><code>VELOX_DYNAMIC_STAGE_NX: Dict[str, Any] = {\n    \"prefix_trg\": \"/ENTRY[entry*]/measurement/eventID[event*]/instrument/stageID[stage]\",\n    \"map\": [(\"design\", \"Stage/HolderType\")],\n    \"map_to_float64\": [\n        (\"tilt1\", ureg.radiant, \"Stage/AlphaTilt\"),\n        (\"tilt2\", ureg.radiant, \"Stage/BetaTilt\"),\n        (\"position\", ureg.meter, [\"Stage/Position/x\", \"Stage/Position/y\", \"Stage/Position/z\"]),\n    ],\n}\n</code></pre></p> <p>The example shows though that it is not necessarily useful to encode all mapping conventions into such dictionaries. Indeed, if there is a mismatch between the reference frames of src and the one used for the trg side, an instruction like concatenate the three values Stage/Position/x, y, z into an array of np.float64 and convert to unit meter may not be sufficient. Offsets or rotations of the reference frame may also be required. In this case, a more complicated mapping dictionary is required. We leave this for now as an open issue for the future and implement such as an explicit mapping and translations as hard-coded instructions instead.</p> <ul> <li>Required keyword prefix_trg specifies the prefix to use when resolving template paths on the trg side excluding the / separator.</li> <li>Required keyword prefix_src specifies the prefix to use when resolving template paths on the src side including separators.</li> <li>Optional keywords follow. Each encodes mapping instructions based on one list of tuples as value.</li> <li>use instructs mapping explicitly instance data on trg without demanding a src.     Specifically, tuples of the following two datatypes are allowed:     (str, str | numpy datatype (scalar or array))     (str, pint.ureg)     The first value resolves the symbol for the concept on the trg side.     The second value resolves the instance data to store on the trg side.     The template path on the trg side is f\"{prefix_trg}/{tpl[0]}\", if provided prefix_src will be ignored.</li> <li> <p>map | map_to_dtype | map_to_dtype_and_join instructs mapping instance data from src on trg.     Differently typed tuples are allowed that encode compact mapping rules to deal with     above-mentioned cases of mismatch. The suffix \"_to*\" is added to solve mismatch 3.     Mismatch cases 1 and 2 are solved based on how the tuple is structured.     Mismatch case 3 is solved by adding a suffix like \"_to_float64\" which will instruct     that the src data will be mapped if possible from original datatype and precision     on the numpy datatype and precision specified by dtype.</p> <p>The suffix _and_join will accept a list of below mentioned tuples to concatenate information.</p> <p>TODO more work needs to be done here</p> <p>Specifically, tuples of the following datatypes are allowed or a str but in only one case: * <code>(str, pint.ureg, str | list[str], pint.ureg)</code> aka case five.   Used in cases of mismatch 1 and 2 with the aim to explicitly convert units between src and trg.</p> <p>The first value resolves the symbol for the concept on the trg side.   The second value resolves the specific unit on the trg side.   The third value resolves the symbol for the concept on the src side.   The fourth value resolves the specific unit on the src side.</p> <p>The third value can be a list of strings of symbols for concepts on the src side.   This is useful for joining individual scalar values in an array,   like x, y, z coordinates.</p> <ul> <li><code>(str, str | list[str], pint.ureg)</code> aka case four.   Used in cases of mismatch 1 with the aim to accept the unit from the src side.</li> </ul> <p>The first value resolves the symbol for the concept on the trg side.   The second value resolves the symbol for the concept on the src side.   The third value resolves the specific unit on the src side.</p> <p>In an implementation, this case can be avoided when the value on the src side   is already normalized into a pint.ureg. The second value can be a list of   strings of symbols for concepts on the src side.</p> <ul> <li><code>(str, pint.ureg, str | list[str])</code> aka case three.   Used in cases of mismatch 1 and 2 with the aim to explicitly convert to   a specific unit on the trg side.</li> </ul> <p>The first value resolves the symbol for the concept on the trg side.   The second value resolves the specific unit on the trg side.   The third value resolves the symbol for the concept on the src side.</p> <p>The third value can be a list of strings of symbols for concepts on the src side.   In an implementation, this case can be avoided when there is another look-up dictionary or   cache from which the unit to use is defined explicitly.   The practical issue with NeXus though is that often concepts are constrained   only as strong as to match a specific unit category, e.g. voltage, i.e. all possible   units that are convertible into the base unit V.</p> <p>Therefore, in practice it makes sense to use this case to be specific about   which unit should be used on the trg side. However, for parsers which cover   many file formats, like pynxtools-em, this will ask people to add potentially duplicated   information. In summary, it is best to use a global look-up dictionary for all concepts   in an application definition and then infer the unit from this dictionary. The actual   unit conversion is performable then e.g. with pint.</p> <ul> <li><code>(str, str | list[str])</code> aka case two.   Used in cases of mismatch 1. Units on src will be carried over onto the trg side.</li> </ul> <p>The first value resolves the symbol for the concept on the trg side.   The second value resolves the symbol for the concept on the src side.</p> <p>The second value can be a list of strings of symbols for concepts on the src side.   This case is an especially useful short-hand notation for concepts with string,   unitless, dimensionless quantities.</p> <ul> <li><code>str</code> aka case one.   Used in cases when symbols on the trg and src side are the same and   units should be carried through as is.</li> </ul> <p>This case is a further simplification for writing even more compact mapping dictionaries.   Python allows for a having a mixture of string and tuples in lists.</p> </li> </ul>"},{"location":"reference/nxs_nion.html","title":"Nion Co. projects with NDATA and HDF5 files","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 metadata/hardware_source/EHT metadata/hardware_source/GeometricProbeSize metadata/hardware_source/ImageRonchigram/C1 ConstW metadata/hardware_source/ImageRonchigram/C10 metadata/hardware_source/ImageRonchigram/C12.a metadata/hardware_source/ImageRonchigram/C12.b metadata/hardware_source/ImageRonchigram/C2 ConstW metadata/hardware_source/ImageRonchigram/C21.a metadata/hardware_source/ImageRonchigram/C21.b metadata/hardware_source/ImageRonchigram/C23.a metadata/hardware_source/ImageRonchigram/C23.b metadata/hardware_source/ImageRonchigram/C3 ConstW metadata/hardware_source/ImageRonchigram/C30 metadata/hardware_source/ImageRonchigram/C32.a metadata/hardware_source/ImageRonchigram/C32.b metadata/hardware_source/ImageRonchigram/C34.a metadata/hardware_source/ImageRonchigram/C34.b metadata/hardware_source/ImageRonchigram/C50 metadata/hardware_source/ImageRonchigram/EHT metadata/hardware_source/ImageRonchigram/GeometricProbeSize metadata/hardware_source/ImageRonchigram/MajorOL metadata/hardware_source/ImageRonchigram/StageOutA metadata/hardware_source/ImageRonchigram/StageOutB metadata/hardware_source/ImageRonchigram/StageOutX metadata/hardware_source/ImageRonchigram/StageOutY metadata/hardware_source/ImageRonchigram/StageOutZ metadata/hardware_source/ImageRonchigram/SuperFEG.^EmissionCurrent metadata/hardware_source/ImageRonchigram/fov_nm metadata/hardware_source/ImageRonchigram/probe_ha metadata/hardware_source/ImageRonchigram/rotation_rad metadata/hardware_source/SuperFEG.^EmissionCurrent metadata/hardware_source/ac_frame_sync metadata/hardware_source/ac_line_sync metadata/hardware_source/autostem/ImageRonchigram/C1 ConstW metadata/hardware_source/autostem/ImageRonchigram/C2 ConstW metadata/hardware_source/autostem/ImageRonchigram/C3 ConstW metadata/hardware_source/autostem/ImageRonchigram/EHT metadata/hardware_source/autostem/ImageRonchigram/GeometricProbeSize metadata/hardware_source/autostem/ImageRonchigram/MajorOL metadata/hardware_source/autostem/ImageRonchigram/StageOutA metadata/hardware_source/autostem/ImageRonchigram/StageOutB metadata/hardware_source/autostem/ImageRonchigram/StageOutX metadata/hardware_source/autostem/ImageRonchigram/StageOutY metadata/hardware_source/autostem/ImageRonchigram/StageOutZ metadata/hardware_source/autostem/ImageRonchigram/SuperFEG.^EmissionCurrent metadata/hardware_source/autostem/ImageRonchigram/fov_nm metadata/hardware_source/autostem/ImageRonchigram/probe_ha metadata/hardware_source/autostem/ImageRonchigram/rotation_rad metadata/hardware_source/autostem/ImageScanned/C1 ConstW metadata/hardware_source/autostem/ImageScanned/C10 metadata/hardware_source/autostem/ImageScanned/C12.a metadata/hardware_source/autostem/ImageScanned/C12.b metadata/hardware_source/autostem/ImageScanned/C2 ConstW metadata/hardware_source/autostem/ImageScanned/C21.a metadata/hardware_source/autostem/ImageScanned/C21.b metadata/hardware_source/autostem/ImageScanned/C23.a metadata/hardware_source/autostem/ImageScanned/C23.b metadata/hardware_source/autostem/ImageScanned/C3 ConstW metadata/hardware_source/autostem/ImageScanned/C30 metadata/hardware_source/autostem/ImageScanned/C32.a metadata/hardware_source/autostem/ImageScanned/C32.b metadata/hardware_source/autostem/ImageScanned/C34.a metadata/hardware_source/autostem/ImageScanned/C34.b metadata/hardware_source/autostem/ImageScanned/C50 metadata/hardware_source/autostem/ImageScanned/EHT metadata/hardware_source/autostem/ImageScanned/GeometricProbeSize metadata/hardware_source/autostem/ImageScanned/MajorOL metadata/hardware_source/autostem/ImageScanned/StageOutA metadata/hardware_source/autostem/ImageScanned/StageOutB metadata/hardware_source/autostem/ImageScanned/StageOutX metadata/hardware_source/autostem/ImageScanned/StageOutY metadata/hardware_source/autostem/ImageScanned/StageOutZ metadata/hardware_source/autostem/ImageScanned/SuperFEG.^EmissionCurrent metadata/hardware_source/autostem/ImageScanned/fov_nm metadata/hardware_source/autostem/ImageScanned/probe_ha metadata/hardware_source/autostem/ImageScanned/rotation_rad metadata/hardware_source/calibration_style metadata/hardware_source/center_x_nm metadata/hardware_source/center_y_nm metadata/hardware_source/channel_modifier metadata/hardware_source/detector_configuration/beam_center_x metadata/hardware_source/detector_configuration/beam_center_y metadata/hardware_source/detector_configuration/bit_depth_image metadata/hardware_source/detector_configuration/bit_depth_readout metadata/hardware_source/detector_configuration/count_time metadata/hardware_source/detector_configuration/countrate_correction_applied metadata/hardware_source/detector_configuration/data_collection_date metadata/hardware_source/detector_configuration/description metadata/hardware_source/detector_configuration/detector_number metadata/hardware_source/detector_configuration/detector_readout_time metadata/hardware_source/detector_configuration/eiger_fw_version metadata/hardware_source/detector_configuration/flatfield_correction_applied metadata/hardware_source/detector_configuration/frame_time metadata/hardware_source/detector_configuration/pixel_mask_applied metadata/hardware_source/detector_configuration/sensor_material metadata/hardware_source/detector_configuration/sensor_thickness metadata/hardware_source/detector_configuration/software_version metadata/hardware_source/detector_configuration/threshold_energy metadata/hardware_source/detector_configuration/x_pixel_size metadata/hardware_source/detector_configuration/x_pixels_in_detector metadata/hardware_source/detector_configuration/y_pixel_size metadata/hardware_source/detector_configuration/y_pixels_in_detector metadata/hardware_source/external_clock_mode metadata/hardware_source/external_clock_wait_time_ms metadata/hardware_source/flyback_time_us metadata/hardware_source/fov_nm metadata/hardware_source/line_time_us metadata/hardware_source/pixel_time_us metadata/hardware_source/probe_ha metadata/hardware_source/rotation_rad metadata/instrument/ImageRonchigram/C1 ConstW metadata/instrument/ImageRonchigram/C10 metadata/instrument/ImageRonchigram/C12.a metadata/instrument/ImageRonchigram/C12.b metadata/instrument/ImageRonchigram/C2 ConstW metadata/instrument/ImageRonchigram/C21.a metadata/instrument/ImageRonchigram/C21.b metadata/instrument/ImageRonchigram/C23.a metadata/instrument/ImageRonchigram/C23.b metadata/instrument/ImageRonchigram/C3 ConstW metadata/instrument/ImageRonchigram/C30 metadata/instrument/ImageRonchigram/C32.a metadata/instrument/ImageRonchigram/C32.b metadata/instrument/ImageRonchigram/C34.a metadata/instrument/ImageRonchigram/C34.b metadata/instrument/ImageRonchigram/C50 metadata/instrument/ImageRonchigram/EHT metadata/instrument/ImageRonchigram/GeometricProbeSize metadata/instrument/ImageRonchigram/MajorOL metadata/instrument/ImageRonchigram/StageOutA metadata/instrument/ImageRonchigram/StageOutB metadata/instrument/ImageRonchigram/StageOutX metadata/instrument/ImageRonchigram/StageOutY metadata/instrument/ImageRonchigram/StageOutZ metadata/instrument/ImageRonchigram/SuperFEG.^EmissionCurrent metadata/instrument/ImageRonchigram/fov_nm metadata/instrument/ImageRonchigram/probe_ha metadata/instrument/ImageRonchigram/rotation_rad metadata/instrument/ImageScanned/C1 ConstW metadata/instrument/ImageScanned/C10 metadata/instrument/ImageScanned/C12.a metadata/instrument/ImageScanned/C12.b metadata/instrument/ImageScanned/C2 ConstW metadata/instrument/ImageScanned/C21.a metadata/instrument/ImageScanned/C21.b metadata/instrument/ImageScanned/C23.a metadata/instrument/ImageScanned/C23.b metadata/instrument/ImageScanned/C3 ConstW metadata/instrument/ImageScanned/C30 metadata/instrument/ImageScanned/C32.a metadata/instrument/ImageScanned/C32.b metadata/instrument/ImageScanned/C34.a metadata/instrument/ImageScanned/C34.b metadata/instrument/ImageScanned/C50 metadata/instrument/ImageScanned/EHT metadata/instrument/ImageScanned/GeometricProbeSize metadata/instrument/ImageScanned/MajorOL metadata/instrument/ImageScanned/StageOutA metadata/instrument/ImageScanned/StageOutB metadata/instrument/ImageScanned/StageOutX metadata/instrument/ImageScanned/StageOutY metadata/instrument/ImageScanned/StageOutZ metadata/instrument/ImageScanned/SuperFEG.^EmissionCurrent metadata/instrument/ImageScanned/fov_nm metadata/instrument/ImageScanned/probe_ha metadata/instrument/ImageScanned/rotation_rad metadata/instrument/autostem/ImageRonchigram/C1 ConstW metadata/instrument/autostem/ImageRonchigram/C2 ConstW metadata/instrument/autostem/ImageRonchigram/C3 ConstW metadata/instrument/autostem/ImageRonchigram/EHT metadata/instrument/autostem/ImageRonchigram/GeometricProbeSize metadata/instrument/autostem/ImageRonchigram/MajorOL metadata/instrument/autostem/ImageRonchigram/StageOutA metadata/instrument/autostem/ImageRonchigram/StageOutB metadata/instrument/autostem/ImageRonchigram/StageOutX metadata/instrument/autostem/ImageRonchigram/StageOutY metadata/instrument/autostem/ImageRonchigram/StageOutZ metadata/instrument/autostem/ImageRonchigram/SuperFEG.^EmissionCurrent metadata/instrument/autostem/ImageRonchigram/fov_nm metadata/instrument/autostem/ImageRonchigram/probe_ha metadata/instrument/autostem/ImageRonchigram/rotation_rad metadata/instrument/autostem/ImageScanned/C10 metadata/instrument/autostem/ImageScanned/C12.a metadata/instrument/autostem/ImageScanned/C12.b metadata/instrument/autostem/ImageScanned/C21.a metadata/instrument/autostem/ImageScanned/C21.b metadata/instrument/autostem/ImageScanned/C23.a metadata/instrument/autostem/ImageScanned/C23.b metadata/instrument/autostem/ImageScanned/C30 metadata/instrument/autostem/ImageScanned/C32.a metadata/instrument/autostem/ImageScanned/C32.b metadata/instrument/autostem/ImageScanned/C34.a metadata/instrument/autostem/ImageScanned/C34.b metadata/instrument/autostem/ImageScanned/C50 metadata/instrument/autostem/ImageScanned/EHT metadata/instrument/autostem/ImageScanned/GeometricProbeSize metadata/instrument/autostem/ImageScanned/StageOutA metadata/instrument/autostem/ImageScanned/StageOutB metadata/instrument/autostem/ImageScanned/StageOutX metadata/instrument/autostem/ImageScanned/StageOutY metadata/instrument/autostem/ImageScanned/StageOutZ metadata/instrument/autostem/ImageScanned/SuperFEG.^EmissionCurrent metadata/instrument/autostem/ImageScanned/fov_nm metadata/instrument/autostem/ImageScanned/probe_ha metadata/instrument/autostem/ImageScanned/rotation_rad metadata/scan/scan_device_parameters/EHT metadata/scan/scan_device_parameters/GeometricProbeSize metadata/scan/scan_device_parameters/SuperFEG.^EmissionCurrent metadata/scan/scan_device_parameters/ac_frame_sync metadata/scan/scan_device_parameters/ac_line_sync metadata/scan/scan_device_parameters/calibration_style metadata/scan/scan_device_parameters/center_x_nm metadata/scan/scan_device_parameters/center_y_nm metadata/scan/scan_device_parameters/channel_modifier metadata/scan/scan_device_parameters/external_clock_mode metadata/scan/scan_device_parameters/external_clock_wait_time_ms metadata/scan/scan_device_parameters/flyback_time_us metadata/scan/scan_device_parameters/fov_nm metadata/scan/scan_device_parameters/line_time_us metadata/scan/scan_device_parameters/pixel_time_us metadata/scan/scan_device_parameters/probe_ha metadata/scan/scan_device_parameters/rotation_rad metadata/scan/scan_device_properties/EHT metadata/scan/scan_device_properties/GeometricProbeSize metadata/scan/scan_device_properties/ImageScanned:C1 ConstW metadata/scan/scan_device_properties/ImageScanned:C10 metadata/scan/scan_device_properties/ImageScanned:C12.a metadata/scan/scan_device_properties/ImageScanned:C12.b metadata/scan/scan_device_properties/ImageScanned:C2 ConstW metadata/scan/scan_device_properties/ImageScanned:C21.a metadata/scan/scan_device_properties/ImageScanned:C21.b metadata/scan/scan_device_properties/ImageScanned:C23.a metadata/scan/scan_device_properties/ImageScanned:C23.b metadata/scan/scan_device_properties/ImageScanned:C3 ConstW metadata/scan/scan_device_properties/ImageScanned:C30 metadata/scan/scan_device_properties/ImageScanned:C32.a metadata/scan/scan_device_properties/ImageScanned:C32.b metadata/scan/scan_device_properties/ImageScanned:C34.a metadata/scan/scan_device_properties/ImageScanned:C34.b metadata/scan/scan_device_properties/ImageScanned:C50 metadata/scan/scan_device_properties/ImageScanned:EHT metadata/scan/scan_device_properties/ImageScanned:GeometricProbeSize metadata/scan/scan_device_properties/ImageScanned:MajorOL metadata/scan/scan_device_properties/ImageScanned:StageOutA metadata/scan/scan_device_properties/ImageScanned:StageOutB metadata/scan/scan_device_properties/ImageScanned:StageOutX metadata/scan/scan_device_properties/ImageScanned:StageOutY metadata/scan/scan_device_properties/ImageScanned:StageOutZ metadata/scan/scan_device_properties/ImageScanned:SuperFEG.^EmissionCurrent metadata/scan/scan_device_properties/ImageScanned:fov_nm metadata/scan/scan_device_properties/ImageScanned:probe_ha metadata/scan/scan_device_properties/ImageScanned:rotation_rad metadata/scan/scan_device_properties/MagBoard 0 DAC 0 metadata/scan/scan_device_properties/MagBoard 0 DAC 1 metadata/scan/scan_device_properties/MagBoard 0 DAC 10 metadata/scan/scan_device_properties/MagBoard 0 DAC 11 metadata/scan/scan_device_properties/MagBoard 0 DAC 2 metadata/scan/scan_device_properties/MagBoard 0 DAC 3 metadata/scan/scan_device_properties/MagBoard 0 DAC 4 metadata/scan/scan_device_properties/MagBoard 0 DAC 5 metadata/scan/scan_device_properties/MagBoard 0 DAC 6 metadata/scan/scan_device_properties/MagBoard 0 DAC 7 metadata/scan/scan_device_properties/MagBoard 0 DAC 8 metadata/scan/scan_device_properties/MagBoard 0 DAC 9 metadata/scan/scan_device_properties/MagBoard 0 Relay metadata/scan/scan_device_properties/MagBoard 1 DAC 0 metadata/scan/scan_device_properties/MagBoard 1 DAC 1 metadata/scan/scan_device_properties/MagBoard 1 DAC 10 metadata/scan/scan_device_properties/MagBoard 1 DAC 11 metadata/scan/scan_device_properties/MagBoard 1 DAC 2 metadata/scan/scan_device_properties/MagBoard 1 DAC 3 metadata/scan/scan_device_properties/MagBoard 1 DAC 4 metadata/scan/scan_device_properties/MagBoard 1 DAC 5 metadata/scan/scan_device_properties/MagBoard 1 DAC 6 metadata/scan/scan_device_properties/MagBoard 1 DAC 7 metadata/scan/scan_device_properties/MagBoard 1 DAC 8 metadata/scan/scan_device_properties/MagBoard 1 DAC 9 metadata/scan/scan_device_properties/MagBoard 1 Relay metadata/scan/scan_device_properties/SuperFEG.^EmissionCurrent metadata/scan/scan_device_properties/ac_frame_sync metadata/scan/scan_device_properties/ac_line_sync metadata/scan/scan_device_properties/calibration_style metadata/scan/scan_device_properties/center_x_nm metadata/scan/scan_device_properties/center_y_nm metadata/scan/scan_device_properties/channel_modifier metadata/scan/scan_device_properties/external_clock_mode metadata/scan/scan_device_properties/external_clock_wait_time_ms metadata/scan/scan_device_properties/flyback_time_us metadata/scan/scan_device_properties/fov_nm metadata/scan/scan_device_properties/line_time_us metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 0 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 1 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 10 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 11 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 2 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 3 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 4 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 5 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 6 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 7 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 8 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 DAC 9 metadata/scan/scan_device_properties/mag_boards/MagBoard 0 Relay metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 0 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 1 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 10 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 11 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 2 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 3 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 4 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 5 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 6 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 7 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 8 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 DAC 9 metadata/scan/scan_device_properties/mag_boards/MagBoard 1 Relay metadata/scan/scan_device_properties/pixel_time_us metadata/scan/scan_device_properties/probe_ha metadata/scan/scan_device_properties/rotation_rad metadata/scan_detector/autostem/ImageScanned/C1 ConstW metadata/scan_detector/autostem/ImageScanned/C10 metadata/scan_detector/autostem/ImageScanned/C12.a metadata/scan_detector/autostem/ImageScanned/C12.b metadata/scan_detector/autostem/ImageScanned/C2 ConstW metadata/scan_detector/autostem/ImageScanned/C21.a metadata/scan_detector/autostem/ImageScanned/C21.b metadata/scan_detector/autostem/ImageScanned/C23.a metadata/scan_detector/autostem/ImageScanned/C23.b metadata/scan_detector/autostem/ImageScanned/C3 ConstW metadata/scan_detector/autostem/ImageScanned/C30 metadata/scan_detector/autostem/ImageScanned/C32.a metadata/scan_detector/autostem/ImageScanned/C32.b metadata/scan_detector/autostem/ImageScanned/C34.a metadata/scan_detector/autostem/ImageScanned/C34.b metadata/scan_detector/autostem/ImageScanned/C50 metadata/scan_detector/autostem/ImageScanned/EHT metadata/scan_detector/autostem/ImageScanned/GeometricProbeSize metadata/scan_detector/autostem/ImageScanned/MajorOL metadata/scan_detector/autostem/ImageScanned/StageOutA metadata/scan_detector/autostem/ImageScanned/StageOutB metadata/scan_detector/autostem/ImageScanned/StageOutX metadata/scan_detector/autostem/ImageScanned/StageOutY metadata/scan_detector/autostem/ImageScanned/StageOutZ metadata/scan_detector/autostem/ImageScanned/SuperFEG.^EmissionCurrent metadata/scan_detector/autostem/ImageScanned/fov_nm metadata/scan_detector/autostem/ImageScanned/probe_ha metadata/scan_detector/autostem/ImageScanned/rotation_rad"},{"location":"reference/rsciio_gatan.html","title":"Gatan DigitalMicrograph DM3/DM4","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 ImageList/TagGroup0/ImageTags/Microscope Info/Actual Magnification ImageList/TagGroup0/ImageTags/Microscope Info/Emission Current (\u00b5A) ImageList/TagGroup0/ImageTags/Microscope Info/Field of View (\u00b5m) ImageList/TagGroup0/ImageTags/Microscope Info/Illumination Mode ImageList/TagGroup0/ImageTags/Microscope Info/Illumination Sub-mode ImageList/TagGroup0/ImageTags/Microscope Info/Imaging Mode ImageList/TagGroup0/ImageTags/Microscope Info/Indicated Magnification ImageList/TagGroup0/ImageTags/Microscope Info/Name ImageList/TagGroup0/ImageTags/Microscope Info/Operation Mode Type ImageList/TagGroup0/ImageTags/Microscope Info/Probe Current (nA) ImageList/TagGroup0/ImageTags/Microscope Info/Probe Size (nm) ImageList/TagGroup0/ImageTags/Microscope Info/Stage Position/Stage Alpha ImageList/TagGroup0/ImageTags/Microscope Info/Stage Position/Stage Beta ImageList/TagGroup0/ImageTags/Microscope Info/Stage Position/Stage X ImageList/TagGroup0/ImageTags/Microscope Info/Stage Position/Stage Y ImageList/TagGroup0/ImageTags/Microscope Info/Stage Position/Stage Z ImageList/TagGroup0/ImageTags/Microscope Info/Voltage"},{"location":"reference/rsciio_velox.html","title":"ThermoFisher Velox EMD","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 Acquisition/AcquisitionStartDatetime/DateTime Acquisition/SourceType Instrument/ControlSoftwareVersion Instrument/InstrumentId Instrument/InstrumentModel Instrument/Manufacturer Optics/AccelerationVoltage Optics/BeamConvergence Optics/CameraLength Optics/Defocus Optics/DoseRate Optics/NominalMagnification Optics/OperatingMode Optics/ScanRotation Optics/TemOperatingSubMode Scan/DwellTime Stage/AlphaTilt Stage/BetaTilt Stage/HolderType Stage/Position/x Stage/Position/y Stage/Position/z electron_source/"},{"location":"reference/tiff_fei.html","title":"FEI Legacy Tagged Image File Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 Camera length Defocus Emission Extraction voltage Filter mode Gun lens Gun type High tension Magnification Metadata.Acquisition.SourceType Metadata.Detectors.ScanningDetector.DetectorName Metadata.Instrument.InstrumentClass Metadata.Instrument.InstrumentID Metadata.Optics.AccelerationVoltage Metadata.Optics.Apertures.Aperture.Diameter Metadata.Optics.BeamCurrent Metadata.Optics.CrossOverOn Metadata.Optics.EucentricWorkingDistance Metadata.Optics.SampleTiltCorrectionOn Metadata.Optics.StigmatorRaw.X Metadata.Optics.StigmatorRaw.Y Metadata.Optics.WorkingDistance Metadata.ScanSettings.DwellTime Metadata.StageSettings.StagePosition.Rotation Metadata.StageSettings.StagePosition.Tilt.Alpha Metadata.StageSettings.StagePosition.Tilt.Beta Metadata.StageSettings.StagePosition.X Metadata.StageSettings.StagePosition.Y Metadata.StageSettings.StagePosition.Z Metadata.VacuumProperties.ElectronChamberPressure Metadata.VacuumProperties.IonChamberPressure Microscope Mode Spot size Stage A Stage B Stage X Stage Y Stage Z Stem rotation Stem rotation correction"},{"location":"reference/tiff_hitachi.html","title":"Hitachi Tagged Image File Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 AcceleratingVoltage EmissionCurrent FilamentCurrent InstructName Instrument name Magnification SerialNumber WorkingDistance"},{"location":"reference/tiff_jeol.html","title":"JEOL Tagged Image File Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 CM_ACCEL_VOLTAGE CM_INSTRUMENT CM_MAG SM_WD"},{"location":"reference/tiff_point.html","title":"point electronic DISS Tagged Image Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 HV/Unit HV/value Mag WD/Unit WD/value"},{"location":"reference/tiff_tescan.html","title":"TESCAN Tagged Image File Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 Device EmissionCurrent HV Magnification PredictedBeamCurrent SerialNumber SpecimenCurrent SpotSize StageRotation StageTilt StageX StageY StageZ StigmatorX StigmatorY WD"},{"location":"reference/tiff_tfs.html","title":"ThermoFisher Tagged Image File Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 Beam/Aperture Beam/ImageMode Beam/Spot Beam/StigmatorX Beam/StigmatorY Detectors/Mode Detectors/Name EBeam/Aperture EBeam/ApertureDiameter EBeam/BeamCurrent EBeam/BeamMode EBeam/DynamicFocusIsOn EBeam/EmissionCurrent EBeam/HV EBeam/UseCase EBeam/WD ETD/Signal Scan/Dwelltime Stage/StageR Stage/StageTa Stage/StageTb Stage/StageX Stage/StageY Stage/StageZ System/BuildNr System/Scan System/Source System/SystemType T1/Signal T2/Signal T3/Signal"},{"location":"reference/tiff_zeiss.html","title":"Zeiss Tagged Image File Format TIFF","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 AP_MAG AP_MANUALKV AP_STAGE_AT_R AP_STAGE_AT_T AP_STAGE_AT_X AP_STAGE_AT_Y AP_STAGE_AT_Z AP_WD DP_SEM SV_SERIAL_NUMBER"},{"location":"reference/zip_png_axon.html","title":"AXON Protochips Portable Network Graphics PNG","text":"<p>The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:</p> Concept NeXus/HDF5 MicroscopeControlImageMetadata.ActivePositionerSettings.PositionerSettings.[*].Stage.Name MicroscopeControlImageMetadata.AuxiliaryData.AuxiliaryDataCategory.[].DataValues.AuxiliaryDataValue.[].HeatingCurrent MicroscopeControlImageMetadata.AuxiliaryData.AuxiliaryDataCategory.[].DataValues.AuxiliaryDataValue.[].HeatingPower MicroscopeControlImageMetadata.AuxiliaryData.AuxiliaryDataCategory.[].DataValues.AuxiliaryDataValue.[].HeatingVoltage MicroscopeControlImageMetadata.AuxiliaryData.AuxiliaryDataCategory.[].DataValues.AuxiliaryDataValue.[].HolderPressure MicroscopeControlImageMetadata.AuxiliaryData.AuxiliaryDataCategory.[].DataValues.AuxiliaryDataValue.[].HolderTemperature MicroscopeControlImageMetadata.MicroscopeSettings.AcceleratingVoltage MicroscopeControlImageMetadata.MicroscopeSettings.BeamBlankerState MicroscopeControlImageMetadata.MicroscopeSettings.CameraLengthValue MicroscopeControlImageMetadata.MicroscopeSettings.MagnificationValue"},{"location":"tutorial/contributing.html","title":"Development guide","text":"<p>This tutorial will guide you through on how to set up a working environment for developing <code>pynxtools-em</code>.</p>"},{"location":"tutorial/contributing.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<ul> <li>You should read the guide on getting started with <code>pynxtools</code>.</li> <li>You should read the installation tutorial.</li> </ul>"},{"location":"tutorial/contributing.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will know</p> <ul> <li>how to setup your environment for developing <code>pynxtools-em</code></li> <li>how to make changes to the software</li> <li>how to test the software</li> <li>how to contribute on GitHub</li> <li>how to use <code>pynxtools-em</code> as a NOMAD plugin</li> </ul>"},{"location":"tutorial/contributing.html#contributing","title":"Contributing","text":"Structure of the <code>pynxtools-em</code> repository <p>The software tools are located inside <code>src/pynxtools_em</code>. They are shipped with unit tests located in <code>tests</code>.</p>"},{"location":"tutorial/contributing.html#setup","title":"Setup","text":"<p>It is recommended to use python 3.12 with a dedicated virtual environment for this package. Learn how to manage python versions and virtual environments. We recommend using <code>uv</code>, an extremely fast manager Python package and project manager. In this tutorial, you will find paralleled descriptions, using either <code>uv</code> or a more classical approach using <code>venv</code> and <code>pip</code>.</p> <p>Start by creating a virtual environment:</p> uvvenv <p><code>uv</code> is capable of creating a virtual environment and install the required Python version at the same time.</p> <pre><code>uv venv --python 3.12\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>python -m venv .venv\n</code></pre> <p>That command creates a new virtual environment in a directory called .venv.</p>"},{"location":"tutorial/contributing.html#development-installation","title":"Development installation","text":"<p>We start by cloning the repository:</p> <pre><code>git clone https://github.com/FAIRmat-NFDI/pynxtools-em.git \\\\\n    --branch main \\\\\n    --recursive pynxtools-em\ncd pynxtools-em\n</code></pre> <p>Next, we install the package in editable mode (together with its dependencies):</p> uvpip <pre><code>uv pip install -e \".[dev]\"\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>pip install --upgrade pip\npip install -e \".[dev]\"\n</code></pre>"},{"location":"tutorial/contributing.html#linting-and-formatting","title":"Linting and formatting","text":"<p>We are using ruff and mypy for linting, formatting, and type checking. It is recommended to use the pre-commit hook available for ruff which formats the code and checks the linting before actually making an actual Git commit.</p> <p>Install the precommit by running</p> <pre><code>pre-commit install\n</code></pre> <p>from the root of this repository.</p>"},{"location":"tutorial/contributing.html#testing","title":"Testing","text":"<p>There exist unit tests for the software written in pytest which can be used as follows:</p> <pre><code>pytest -sv tests\n</code></pre>"},{"location":"tutorial/contributing.html#editing-the-documentation","title":"Editing the documentation","text":"<p>We are using `mkdocs for the documentation. If you edit the documentation, you can build it locally. For this, you need to install an additional set of dependencies:</p> uvpip <pre><code>uv pip install -e \".[docs]\"\n</code></pre> <pre><code>pip install -e \".[docs]\"\n</code></pre> <p>You can then serve the documentation locally by running</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"tutorial/contributing.html#contributing-to-the-package-on-github","title":"Contributing to the package on GitHub","text":"<p>Once you are happy with the changes, please commit them on a separate branch and create a pull request on GitHub. We run a number of GitHub actions that check the correct linting, run the tests in an isolated environment, and build the documentation. Once these pass and a peer review of the code has occurred, your code will be accepted.</p>"},{"location":"tutorial/contributing.html#developing-pynxtools-em-as-a-nomad-plugin","title":"Developing <code>pynxtools-em</code> as a NOMAD plugin","text":"<p>If you plan to contribute to the NOMAD plugin functionality of pynxtools-em, it often makes sense to use the NOMAD development environment called <code>nomad-distro-dev</code>. You can learn more in the NOMAD documentation.</p>"},{"location":"tutorial/contributing.html#troubleshooting","title":"Troubleshooting","text":"<p>If you face any issues with the tool or when setting up the development environment, please create a new Github Issue.</p>"},{"location":"tutorial/examples.html","title":"Examples","text":""},{"location":"tutorial/examples.html#how-to-ingest-different-information-sources","title":"How to ingest different information sources","text":"<p>pynxtools-em provides a set of parsers that standardize diverse content stored from several proprietary and open-source data models into NeXus. The tool needs to serve different methods how information should be combined given that in reality a single source of information like an ELN or a file format does not necessarily store all pieces of information which one may have serialized using NeXus. For this reason pynxtools-em uses supplementary text files for now which exemplify how information missing in one serialization format can be supplemented and ingested during the parsing. This part of the documentation lists these file formats.</p> <p>nxem.schema.archive.yaml is a YAML file representing a custom NOMAD Oasis ELN schema whereby users can collect metadata which are typically not stored in files provided by technology partners.</p> <p>eln_data.yaml is a YAML/text file which contains relevant data which are typically not contained in files from technology partners. These data are typically collected either by editing the file manually or by using an electronic lab notebook (ELN) such as the NOMAD ELN. Every other ELN can be used with this parser provided that this ELN writes its data into a YAML file with the same keywords and structure as it is exemplified in the above-mentioned YAML file.</p> <p>em.oasis.specific.yaml is a YAML/text file which contains additional metadata and configuration details that are not necessarily defined via an ELN but which should be considered during parsing. One use case where this file is ideal is for passing frequent metadata that are often the same when using pynxtools-em. The oasis.specific config file can be used to offload once the entering of these pieces of information to render the ELN more succinct and focused on collecting those metadata that do change frequently. A typical example is a lab where one uses always the same microscope such that many (static) details of the microscope are expected to end up in the static section of the NXem application definition i.e. /NXem/ENTRY/measurement/instrument</p>"},{"location":"tutorial/examples.html#documenting-reference-frame-conventions","title":"Documenting reference frame conventions","text":"<p>Unambiguous and complete documentation of all reference frames used or assumed is a necessary requirement to make every study of crystal orientations understandable and interpretable.</p> <p>em.conventions.schema.archive.yaml is a YAML file representing a custom NOMAD Oasis ELN schema whereby users can document these conventions and export them into an eln_data.yaml file.</p> <p>em.conventions.yaml is an example of one such resulting YAML file that can be used as additional input to pynxtools-em to add respective conventions as additional content in the generated NeXus/HDF5 file.</p>"},{"location":"tutorial/installation.html","title":"Installation guide","text":""},{"location":"tutorial/installation.html#what-should-you-should-know-before-this-tutorial","title":"What should you should know before this tutorial?","text":"<p>To get started, it does not hurt to read the following <code>pynxtools</code> tutorial:</p> <ul> <li>Guide on getting started with <code>pynxtools</code>, NeXus, and NOMAD</li> <li>Installation tutorial for <code>pynxtools</code></li> </ul>"},{"location":"tutorial/installation.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will know</p> <ul> <li>how to install <code>pynxtools-em</code></li> <li>how to install <code>pynxtools-em</code> together with NOMAD</li> </ul>"},{"location":"tutorial/installation.html#setup","title":"Setup","text":"<p>It is recommended to use python 3.12 with a dedicated virtual environment for this package. Learn how to manage python versions and virtual environments.</p> <p>There are many alternatives to managing virtual environments and package dependencies (requirements). We recommend using <code>uv</code>, an extremely fast manager Python package and project manager. In this tutorial, you will find paralleled descriptions, using either <code>uv</code> or a more classical approach using <code>venv</code> and <code>pip</code>.</p> <p>Start by creating a virtual environment:</p> uvvenv <p><code>uv</code> is capable of creating a virtual environment and install the required Python version at the same time.</p> <pre><code>uv venv --python 3.12\n</code></pre> <p>Note that you will need to install the Python version manually beforehand.</p> <pre><code>python -m venv .venv\n</code></pre> <p>That command creates a new virtual environment in a directory called <code>.venv</code>.</p>"},{"location":"tutorial/installation.html#installation","title":"Installation","text":"<p>Install the latest stable version of this package from PyPI with</p> uvpip <pre><code>uv pip install pynxtools-em\n</code></pre> <pre><code>pip install pynxtools-em\n</code></pre> <p>You can also install the latest development version with</p> uvpip <pre><code>uv pip install git+https://github.com/FAIRmat-NFDI/pynxtools-em.git\n</code></pre> <pre><code>pip install git+https://github.com/FAIRmat-NFDI/pynxtools-em.git\n</code></pre>"},{"location":"tutorial/installation.html#how-to-install-pynxtools-em-with-nomad","title":"How to install <code>pynxtools-em</code> with NOMAD","text":"<p>To use <code>pynxtools-em</code> with NOMAD, simply install it in the same environment as the <code>nomad-lab</code> package. NOMAD will recognize <code>pynxtools-em</code> as a plugin automatically. In addition, NOMAD will install a schema for NeXus application definitions.</p>"},{"location":"tutorial/installation.html#start-using-pynxtools-em","title":"Start using <code>pynxtools-em</code>","text":"<p>That's it! You can now use <code>pynxtools-em</code>!</p>"},{"location":"tutorial/nexusio.html","title":"How to use a NeXus/HDF5 file","text":""},{"location":"tutorial/oasis.html","title":"Convert data to NeXus using NOMAD Oasis","text":""},{"location":"tutorial/standalone.html","title":"Convert electron microscopy data and metadata to NeXus","text":""},{"location":"tutorial/standalone.html#who-is-this-tutorial-for","title":"Who is this tutorial for?","text":"<p>This document is for people who want to standardize their research data by converting these into a NeXus standardized format.</p>"},{"location":"tutorial/standalone.html#what-should-you-know-before-this-tutorial","title":"What should you know before this tutorial?","text":"<ul> <li>You should have a basic understanding of FAIRmat NeXus and pynxtools</li> <li>You should have a basic understanding of using Python and Jupyter notebooks via JupyterLab</li> </ul>"},{"location":"tutorial/standalone.html#what-you-will-know-at-the-end-of-this-tutorial","title":"What you will know at the end of this tutorial?","text":"<p>You will have a basic understanding how to use pynxtools-em for converting your EM data to a NeXus/HDF5 file.</p>"},{"location":"tutorial/standalone.html#steps","title":"Steps","text":""},{"location":"tutorial/standalone.html#installation","title":"Installation","text":"<p>See here for how to install pynxtools together with the EM reader plugin. Note that the reader is a combination of multiple readers each supporting a different set of versions of file formats used by key technology partners from the field of electron microscopy.</p>"},{"location":"tutorial/standalone.html#running-the-reader-from-the-command-line","title":"Running the reader from the command line","text":"<p>An example script to run the EM reader in <code>pynxtools</code>:</p> <pre><code>user@box:~$ dataconverter $&lt;em-file path&gt; $&lt;em-file path&gt; $&lt;eln-file path&gt; --reader em --nxdl NXem --output &lt;output-file path&gt;.nxs\n</code></pre> <p>Note that typically none of the supported file formats have data/values for all required and recommended fields and attributes in <code>NXem</code>. In order for the validation step of the EM reader to pass, you need to provide an ELN file that contains the missing values if you would like to be fully compliant with the NXem standard.</p>"},{"location":"tutorial/standalone.html#examples","title":"Examples","text":"<p>You can find examples how to use <code>pynxtools-em</code> for your EM research data pipeline in <code>src/pynxtools_em/nomad/examples</code>. These are designed for working with <code>NOMAD</code> and its <code>NOMAD Remote Tools Hub (NORTH)</code>.</p> <p>Congrats! You now have a FAIR NeXus file!</p>"}]}