{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9345cb-46bf-4df3-9dac-1bde062d9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(f\"../src\")\n",
    "from pynxtools_em.parsers.hfive_base import HdfFiveBaseParser, NXEM_VOLATILE_NAMED_HDF_PATHS, NXEM_VOLATILE_SUFFIX_HDF_PATHS\n",
    "print(os.getcwd())\n",
    "! mkdir -p prod && mkdir -p log && which python\n",
    "! pip list | grep pynxtools*\n",
    "import matplotlib\n",
    "print(matplotlib.get_backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73587f5a-076f-4f58-9dbf-f55fb4d363e0",
   "metadata": {},
   "source": [
    "## Example how to find all unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e096b-603b-4ed1-bd01-eb50330cce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_dir = False\n",
    "test_case_directories = set()\n",
    "for root, dirnames, files in os.walk(os.getcwd()):\n",
    "    for filename in files:  # loop through files in the current directory\n",
    "        file_name = os.path.join(root, filename)\n",
    "        if file_name.startswith(f\"{os.getcwd()}/data/\"):\n",
    "            test_case_name = file_name[0:file_name.rfind(\"/\")].replace(f\"{os.getcwd()}/data/\", \"\")\n",
    "            if not test_case_name.startswith(\"/home\"):\n",
    "                test_case_directories.add(test_case_name)\n",
    "        del file_name\n",
    "for test_case in sorted(test_case_directories):\n",
    "    print(test_case)\n",
    "    for subdir in [\"prod\", \"log\", \"reference\"]:\n",
    "        fpath = f\"{os.getcwd()}/{subdir}/{test_case}\"\n",
    "        if not(os.path.exists(fpath) and os.path.isdir(fpath)):\n",
    "            if mk_dir:\n",
    "                os.mkdir(fpath)\n",
    "        del fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1302e-4c69-4f4e-8b09-86f98105b6e9",
   "metadata": {},
   "source": [
    "## Generate list of all tests for code launch.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475f074-3ff8-4cb5-aeac-b4e4601ad8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_case in sorted(test_case_directories):\n",
    "    file_list = os.listdir(f\"{os.getcwd()}/data/{test_case}\")\n",
    "    # for file_name in file_list:\n",
    "    #    print(f'''                     //\"tests/data/{test_case}/{file_name}\",''')\n",
    "    # print(f'''                     //\"tests/prod/{test_case}/output.nxs\"]''')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a351a5-940d-4891-bb7e-1f4ba4100f6d",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a88fe-5e4f-4429-b668-8a7956210606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_parser = True\n",
    "verbose = True\n",
    "whitelist = []\n",
    "blacklist = []\n",
    "n_tests = 0\n",
    "bash_script_lines = [\"#!/bin/sh\", \"\"]\n",
    "for test_case in sorted(test_case_directories):\n",
    "    if len(whitelist) > 0:\n",
    "        if test_case not in whitelist:\n",
    "            continue\n",
    "    if len(blacklist) > 0:\n",
    "        if test_case in blacklist:\n",
    "            continue\n",
    "\n",
    "    print(f\"- [ ] {test_case}\")  # , {len(file_list)}\")\n",
    "    curr_dir = f\"{os.getcwd()}/data/{test_case}\"\n",
    "    file_list = os.listdir(curr_dir)\n",
    "    out = f\"{os.getcwd()}/prod/{test_case}/output.nxs\"  # data.{parser_type}.{entry}.nxs\"\n",
    "    stdout = f\"{os.getcwd()}/log/{test_case}/stdout.{test_case}.txt\"\n",
    "    stderr = f\"{os.getcwd()}/log/{test_case}/stderr.{test_case}.txt\"\n",
    "    bash_script_lines.append(f'''echo \"{test_case}\"''')\n",
    "    if len(file_list) == 1:\n",
    "        in_one = f\"{curr_dir}/{file_list[0]}\"\n",
    "        if run_parser:\n",
    "            # ! dataconverter $in_one --reader em --nxdl NXem --output $out 1>$stdout 2>$stderr\n",
    "            bash_script_lines.append(f\"dataconverter {in_one} --reader em --nxdl NXem --output {out} 1>{stdout} 2>{stderr}\")\n",
    "            n_tests += 1\n",
    "        del in_one\n",
    "    elif len(file_list) == 2:\n",
    "        in_one = f\"{curr_dir}/{file_list[0]}\"\n",
    "        in_two = f\"{curr_dir}/{file_list[1]}\"\n",
    "        if run_parser:\n",
    "            # ! dataconverter $in_one $in_two --reader em --nxdl NXem --output $out 1>$stdout 2>$stderr\n",
    "            bash_script_lines.append(f\"dataconverter {in_one} {in_two} --reader em --nxdl NXem --output {out} 1>{stdout} 2>{stderr}\")\n",
    "            n_tests += 1\n",
    "        del in_one, in_two\n",
    "    elif len(file_list) == 3:\n",
    "        in_one = f\"{curr_dir}/{file_list[0]}\"\n",
    "        in_two = f\"{curr_dir}/{file_list[1]}\"\n",
    "        in_three = f\"{curr_dir}/{file_list[2]}\"\n",
    "        if run_parser:\n",
    "            # ! dataconverter $in_one $in_two $in_three --reader em --nxdl NXem --output $out 1>$stdout 2>$stderr\n",
    "            bash_script_lines.append(f\"dataconverter {in_one} {in_two} {in_three} --reader em --nxdl NXem --output {out} 1>{stdout} 2>{stderr}\")\n",
    "            n_tests += 1\n",
    "        del in_one, in_two, in_three\n",
    "    del file_list, curr_dir, out, stdout, stderr\n",
    "print(f\"Ran {n_tests} tests\")\n",
    "with open(f\"{os.getcwd()}/run_tests.sh\", \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(bash_script_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb878848-c966-4163-8235-f2e8eff4c4c4",
   "metadata": {},
   "source": [
    "## Example how to generate a reference artifact from a NeXus file for unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a14fc5-6ce8-4ceb-a837-dfe7586b6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = []\n",
    "blacklist = []\n",
    "for test_case in sorted(test_case_directories):\n",
    "    if len(whitelist) > 0:\n",
    "        if test_case not in whitelist:\n",
    "            continue\n",
    "    if len(blacklist) > 0:\n",
    "        if test_case in blacklist:\n",
    "            continue           \n",
    "    print(f\"- [ ] {test_case}\")\n",
    "    fpath_in = f\"{os.getcwd()}/prod/{test_case}/output.nxs\"\n",
    "    fpath_out = f\"{os.getcwd()}/reference/{test_case}/output.nxs.sha256.ref.yaml\"\n",
    "    try:\n",
    "        hfive_parser = HdfFiveBaseParser(file_path=fpath_in, hashing=True, verbose=False)\n",
    "        hfive_parser.get_content()\n",
    "        hfive_parser.store_hashes(\n",
    "            blacklist_by_key=NXEM_VOLATILE_NAMED_HDF_PATHS,\n",
    "            blacklist_by_suffix=NXEM_VOLATILE_SUFFIX_HDF_PATHS,\n",
    "            file_path=fpath_out)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"- [ ] >>>> ERROR >>>> {test_case}\")\n",
    "    del fpath_in, fpath_out, hfive_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24abc8aa-2f9e-4a7d-b656-2cf204fdec15",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6646efb-adfc-4d4c-a449-f7ed030aefed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
