{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea726bb-b38c-4277-ab0b-2a18711e110b",
   "metadata": {},
   "source": [
    "## Analyze parsed metadata from nionswift to improve mapping onto NXem for the nxs_nion parser of pynxtools-em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f0874-cc85-4cdd-93b4-32f9a5c60be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from ast import literal_eval\n",
    "from ase.data import chemical_symbols\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"{os.getcwd()}\")\n",
    "\n",
    "directory = \"CHANGEME\".replace(\"/\", f\"{os.path.sep}\")\n",
    "print(directory)\n",
    "# serialized_axes = \"[{'offset': -0.07421380365287618, 'scale': 7.247441762976189e-05, 'units': 'rad'}, {'offset': -0.07421380365287618, 'scale': 7.247441762976189e-05, 'units': 'rad'}]\"\n",
    "# serialized_dims = \"(1,)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81147a03-92d8-4637-b5c6-91b96c10d96e",
   "metadata": {},
   "source": [
    "### Variants of NXdata taken and how to interpret these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ec9bf6-256c-4e08-acf6-ee18b567136a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def deserialize_to_list_of_axes(serialized: str) -> list[dict[str, float | int | str]]:\n",
    "    \"\"\"Deserialize into a list of dictionaries each representing a physical dimension axis.\"\"\"\n",
    "    deserialized = literal_eval(serialized)\n",
    "    any_dict_not_an_axis = False\n",
    "    for obj in deserialized:\n",
    "        if isinstance(obj, dict):\n",
    "            if (\n",
    "                all(key in obj for key in (\"offset\", \"scale\", \"units\"))\n",
    "                and len(obj.keys()) == 3\n",
    "            ):\n",
    "                continue\n",
    "        any_dict_not_an_axis = True\n",
    "    if not any_dict_not_an_axis:\n",
    "        return deserialized\n",
    "    return []\n",
    "\n",
    "\n",
    "# print(deserialize_to_list_of_axes(serialized_axes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5dbcd15-18cf-4728-a659-fe10d38f385a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def deserialize_to_tuple_of_dimensions(serialized: str) -> tuple[int]:\n",
    "    \"\"\"Deserialize to a typical return value as of np.shape().\"\"\"\n",
    "    deserialized = literal_eval(serialized)\n",
    "    if isinstance(deserialized, tuple):\n",
    "        if all(isinstance(value, int) for value in deserialized):\n",
    "            return deserialized\n",
    "    return ()\n",
    "\n",
    "\n",
    "# print(deserialize_to_tuple_of_dimensions(serialized_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae24769-2225-409c-a5e5-8de5f9bb4867",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_axes(list_of_axes: list[dict[str, float | int | str]]) -> str:\n",
    "    \"\"\"Create a token of the sorted axes to identify the sub-space in phase space.\"\"\"\n",
    "    token = []\n",
    "    for axis in list_of_axes:\n",
    "        if axis[\"units\"] == \"\":\n",
    "            token.append(\"unitless\")\n",
    "        else:\n",
    "            token.append(axis[\"units\"])\n",
    "    return \";\".join(token)\n",
    "\n",
    "\n",
    "# print(tokenize_axes(deserialize_to_list_of_axes(serialized_axes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff4b79-9243-4787-a78d-5dc52870367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsproj_to_eln = {}\n",
    "# identify for which projects we should have collected logfiles\n",
    "with open(f\"{directory}{os.sep}script{os.sep}nsproj_to_eln.yaml\") as fp:\n",
    "    nsproj_to_eln = yaml.safe_load(fp)\n",
    "eln_to_nsproj = {}\n",
    "for nsproj, eln in nsproj_to_eln.items():\n",
    "    if eln not in eln_to_nsproj:\n",
    "        eln_to_nsproj[eln] = nsproj\n",
    "    else:\n",
    "        print(f\"WARNING::Duplicated key for {nsproj} !\")\n",
    "del nsproj, eln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199acab9-f92e-4da6-a00c-b1f5326217a6",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px; border-left:5px solid #f39c12; background:#fdf5e6;\">\n",
    "<b>⚠️ Warning:</b> We need to prefix everything with project IDs in the future as users tend to keep copies nsproject files that have the same binary content!.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3bd045-cb9c-4483-86c9-0d3cc4fef27d",
   "metadata": {},
   "source": [
    "### Run and analyze projects that have not yet been touched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f435f8-9697-4657-a76d-fd1ed00ddc9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "analyze_untouched_projects = False\n",
    "if (\n",
    "    analyze_untouched_projects\n",
    "):  # identify for which projects we should collect a logfile\n",
    "    nsproj_expected: str = set()\n",
    "    with open(f\"{directory}{os.sep}script{os.sep}nsproj_to_eln.yaml\") as fp:\n",
    "        nsproj_to_eln = yaml.safe_load(fp)\n",
    "        # identify all possible project, based on step02.*.ods configuration file from run02\n",
    "        for remote_nsproj_rel_fpath, remote_eln_abs_fpath in nsproj_to_eln.items():\n",
    "            clean_hash = f\"{remote_eln_abs_fpath.replace('/scratch/pynxtools-em/', '').replace('.eln_data.yaml', '')}.log\"\n",
    "            # print(clean_hash)\n",
    "            if clean_hash not in nsproj_expected:\n",
    "                nsproj_expected.add(clean_hash)\n",
    "            else:\n",
    "                \"\"\"\n",
    "                if remote_nsproj_rel_fpath not in (\"../../nion_data/Haas/GaN_NWs_N3757_holey_C_new_60kV/GaN_NWs_N3757_holey_C_new_60kV.nsproj\",\n",
    "                                                   \"../../nion_data/Haas/2020-12-01_SbOx_6M/.ipynb_checkpoints/2020-12-01_SbOx_6M-checkpoint.nsproj\",\n",
    "                                                   \"../../nion_data/Haas/2020-12-01_SbOx_6M/2020-12-01_SbOx_6M.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/06Oct2022_BTO-STO-Trilayer.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/2022/01Nov2022_STO-BTO-Superlattice/01Nov2022_STO-BTO-Superlattice.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/2022/02Nov2022_STO-BTO-Superlattice Data/02Nov2022_STO-BTO-Superlattice_200kV.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/2024/MBE_060/Lamelle_1/29Jan_2024_DPC Data/2024_29Jan_MBE060_Lamelle_1.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/A1212_22-06-2021/A1212_22-06-2021.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/A1213_22-09-2021/20210922 sample A.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/A1213_22-09-2021/20210923 sample A.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/BTO lamella 2/Idle.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Ga2O3_Lamelle_2/02March2023_Ga2O3_4D-STEM/02March2023_Ga2O3_4D-STEM.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Ga2O3_Lamelle_2/15Dez2022_Ga2O3.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Ga2O3_Lamelle_2/27Feb2023_Ga2O3 Data/27Feb2023_Ga2O3.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/HU1-2422-GaP/HU1-2422_GaP_05Juni2023.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Superlattice_STO_BTO/STO_BTO_Lamelle_July2023/Lamelle_1/STO_BTO_July2023_Lamelle_1.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Superlattice_STO_BTO/STO_BTO_Lamelle_July2023/Lamelle_1/STO_BTO_Lamelle_1_18July2023.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Superlattice_STO_BTO/STO_BTO_Lamelle_July2023/Lamelle_2/STO_BTO_Lamelle_2_18July2023.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/Superlattice_STO_BTO/STO_BTO_Lamelle_July2023/Lamelle_2/STO_BTO_Lamelle_2_19July2023.nsproj\",\n",
    "                                                   \"../../nion_data/Haeusler/b-Ga2O3_Sam/b-Ga2O3_Sam_29June2023.nsproj\",\n",
    "                                                   \"../../nion_data/Hongguang/New folder/20220615 HZO 3nm 01.nsproj\",\n",
    "                                                   \"../../nion_data/Nerl/23-05-26_hBN-G-Ag_het_E5_box_737.nsproj\",\n",
    "                                                   \"../../nion_data/Nerl/23-11-24_WSe2_box 12634/23-11-24_WSe2_box 12634.nsproj\",\n",
    "                                                   \"../../nion_data/Nerl/25-09-19-AlGaBiAs-EELS/AlGaBiAs_EELS_20250919.nsproj\",\n",
    "                                                   \"../../nion_data/Nerl/Nerl-20-2-25_d1+2/25-02-20_Al-bowtie_nerl.nsproj\",\n",
    "                                                   \"../../nion_data/Nerl/Nerl-20-2-25_d3/25-02-25-al G hbn nerl.nsproj\",\n",
    "                                                   \"../../nion_data/Nerl/S14 Franz/25-02-26_Franz_S14.nsproj\"):\n",
    "                # accidentally .ipynb_checkpoints where included and these have sometimes duplicated nsproj files\n",
    "                \"\"\"\n",
    "                # print(f\"{remote_nsproj_rel_fpath}\")\n",
    "                print(f\"WARNING::{remote_nsproj_rel_fpath} is a duplicated hash\")\n",
    "            del clean_hash\n",
    "    print(\n",
    "        f\"{len(nsproj_expected)} projects ought to have logfiles as these are the only nsproj file, or a single instance of copies of the same nsproj file in different directories\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b723e1b3-f1ea-4396-87ad-0161315ee878",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    analyze_untouched_projects\n",
    "):  # identify for which projects we have already collected such a logfile\n",
    "    nsproj_processed: str = set()\n",
    "    cnt = 0\n",
    "    for root, dirs, files in os.walk(f\"{directory}{os.sep}log\"):\n",
    "        for file in files:\n",
    "            fpath = f\"{root}/{file}\".replace(os.sep * 2, os.sep)\n",
    "            if not fpath.endswith(\".log\"):\n",
    "                continue\n",
    "            # check if logfile has errors\n",
    "            cnt += 1\n",
    "            # print(cnt)\n",
    "            with open(fpath) as fp:\n",
    "                for dirty_line in fp.readlines():\n",
    "                    match = re.search(r\"^ERROR\", dirty_line)\n",
    "                    if not match:\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(dirty_line)\n",
    "                        break\n",
    "            continue\n",
    "            clean_hash = f\"{fpath[fpath.rfind(os.sep) + 1 :]}\"\n",
    "            if clean_hash not in nsproj_processed:\n",
    "                nsproj_processed.add(clean_hash)\n",
    "            else:\n",
    "                raise ValueError(\"Duplicated hash\")\n",
    "            del clean_hash\n",
    "    print(f\"{len(nsproj_processed)} projects have logfiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8613dc71-a1d6-4743-b0dd-77b48647bf03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if (\n",
    "    analyze_untouched_projects\n",
    "):  # given two sets return those from expected which are not in processed\n",
    "    pass\n",
    "    \"\"\"\n",
    "    nsproj_missing: str = nsproj_expected.difference(nsproj_processed)\n",
    "    for entry in nsproj_missing:\n",
    "        eln_data_yaml_file_missing = f\"/scratch/pynxtools-em/{entry.replace('.log', '')}.eln_data.yaml\"\n",
    "        # print(eln_data_yaml_file_missing)\n",
    "        for key, val in nsproj_to_eln.items():  # naive brute force ok, as not too many entries\n",
    "            if eln_data_yaml_file_missing == f\"{val.replace('.log', '')}\":\n",
    "                print(f\">>>> {key} found\")\n",
    "                break\n",
    "        del eln_data_yaml_file_missing\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347462fa-16de-4d00-849d-aca6d8aa17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nxdata_types = [\n",
    "    \"nm;nm\",\n",
    "    \"eV\",\n",
    "    \"nm;nm;eV\",\n",
    "    \"unitless;nm;nm\",\n",
    "    \"rad;rad\",\n",
    "    \"unitless;eV\",\n",
    "    \"unitless;nm;nm;eV\",\n",
    "    \"unitless;unitless;eV\",\n",
    "    \"unitless\",\n",
    "    \"rad;eV\",\n",
    "    \"nm;nm;unitless;eV\",\n",
    "    \"unitless;unitless\",\n",
    "    \"1/nm;1/nm\",\n",
    "    \"unitless;rad;eV\",\n",
    "    \"unitless;unitless;unitless\",\n",
    "    \"nm;nm;rad;rad\",\n",
    "    \"eV;nm;nm\",\n",
    "    \"nm;nm;rad;eV\",\n",
    "    \"unitless;rad;rad\",\n",
    "    \"nm\",\n",
    "    \"rad\",\n",
    "    \"unitless;unitless;unitless;unitless\",\n",
    "    \"iteration\",\n",
    "    \"unitless;nm;nm;unitless;eV\",\n",
    "    \"nm;nm;unitless;unitless\",\n",
    "    \"1/;1/\",\n",
    "    \"unitless;nm\",\n",
    "    \"nm;eV\",\n",
    "    \"nm;rad;eV\",\n",
    "    \"nm;nm;unitless\",\n",
    "    \"nm;nm;rad\",\n",
    "    \"1/nm\",\n",
    "    \"unitless;unitless;rad;rad\",\n",
    "    \"unitless;unitless;unitless;unitless;unitless\",\n",
    "    \"unitless;nm;nm;rad;rad\",\n",
    "    \"1/rad;1/rad\",\n",
    "    \"1/eV\",\n",
    "    \"rad;rad;rad;rad\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1f9149-0fce-4d0e-8c20-18a20dd51ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11275\t0.3267\tnm;nm\n",
      "4161\t0.4473\teV\n",
      "3172\t0.5392\tnm;nm;eV\n",
      "3138\t0.6301\tunitless;nm;nm\n",
      "3053\t0.7186\trad;rad\n",
      "2686\t0.7964\tunitless;eV\n",
      "1168\t0.8303\tunitless;nm;nm;eV\n",
      "801\t0.8535\tunitless;unitless;eV\n",
      "650\t0.8723\tunitless\n",
      "633\t0.8907\trad;eV\n",
      "498\t0.9051\tnm;nm;unitless;eV\n",
      "485\t0.9192\tunitless;unitless\n",
      "328\t0.9287\t1/nm;1/nm\n",
      "312\t0.9377\tunitless;rad;eV\n",
      "300\t0.9464\tunitless;unitless;unitless\n",
      "294\t0.9549\tnm;nm;rad;rad\n",
      "276\t0.9629\teV;nm;nm\n",
      "222\t0.9693\tnm;nm;rad;eV\n",
      "220\t0.9757\tunitless;rad;rad\n",
      "207\t0.9817\tnm\n",
      "202\t0.9876\trad\n",
      "183\t0.9929\tunitless;unitless;unitless;unitless\n",
      "115\t0.9962\titeration\n",
      "44\t0.9975\tunitless;nm;nm;unitless;eV\n",
      "14\t0.9979\tnm;nm;unitless;unitless\n",
      "14\t0.9983\t1/;1/\n",
      "12\t0.9986\tunitless;nm\n",
      "8\t0.9989\tnm;eV\n",
      "8\t0.9991\tnm;rad;eV\n",
      "8\t0.9993\tnm;nm;unitless\n",
      "7\t0.9995\tnm;nm;rad\n",
      "4\t0.9997\t1/nm\n",
      "4\t0.9998\tunitless;unitless;rad;rad\n",
      "2\t0.9998\tunitless;unitless;unitless;unitless;unitless\n",
      "2\t0.9999\tunitless;nm;nm;rad;rad\n",
      "2\t0.9999\t1/rad;1/rad\n",
      "1\t1.0\t1/eV\n",
      "1\t1.0\trad;rad;rad;rad\n"
     ]
    }
   ],
   "source": [
    "pivot_dims = []\n",
    "total_cnts = 0\n",
    "for key, cnts in stats_axes.items():\n",
    "    pivot_dims.append((cnts, key))\n",
    "    total_cnts += cnts\n",
    "pivot_dims.sort(key=lambda x: x[0], reverse=True)\n",
    "sum_cnts = 0\n",
    "for cnts, key in pivot_dims:\n",
    "    sum_cnts += cnts\n",
    "    print(f\"{cnts}\\t{np.around(sum_cnts / total_cnts, decimals=4)}\\t{key}\")\n",
    "    # print(f'''\"{key}\",''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6bf964-131b-4a9b-8d20-cd6bd23eec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Voting based on user name and atomtypes\n",
    "user_name_aliases = [\n",
    "    \"March\",\n",
    "    \"Kirmse\",\n",
    "    \"Haas\",\n",
    "    \"Fairman\",\n",
    "    \"Kammerer\",  # \"Kammerer;Jochen\",\n",
    "    \"Wagner\",\n",
    "    \"Krivanek\",\n",
    "    \"AEljarrat\",\n",
    "    \"Repa\",\n",
    "    \"Pekin\",\n",
    "    \"Bruker\",\n",
    "    \"McCauley\",\n",
    "    \"Haeusler\",\n",
    "    \"Coogan\",\n",
    "    \"Elgvin\",\n",
    "    \"Zhao\",\n",
    "    \"Kochovski\",\n",
    "    \"Wargulski\",\n",
    "    \"Mueller\",\n",
    "    \"Gladyshev\",\n",
    "    \"Hongguang\",\n",
    "    \"Mogilatenko\",\n",
    "]\n",
    "\n",
    "voting_based_on_user_name = {}\n",
    "voting_based_on_atom_types = {}\n",
    "nsprojects = pd.read_excel(\n",
    "    f\"{directory}{os.sep}step02_nion_data_metadata.ods\", engine=\"odf\"\n",
    ")\n",
    "project_id = 0\n",
    "project_id_start = 1\n",
    "project_id_end = 670\n",
    "for row in nsprojects.itertuples(index=True):\n",
    "    if row.parse == 1:\n",
    "        project_id += 1\n",
    "        if (project_id < project_id_start) or (project_id > project_id_end):\n",
    "            continue\n",
    "\n",
    "        voting_based_on_user_name[row.nsproj_fpath] = {}\n",
    "        for user_name_alias in user_name_aliases:\n",
    "            voting_based_on_user_name[row.nsproj_fpath][user_name_alias] = 0\n",
    "        if row.user_name_alias in voting_based_on_user_name[row.nsproj_fpath]:\n",
    "            voting_based_on_user_name[row.nsproj_fpath][row.user_name_alias] = 1\n",
    "\n",
    "        voting_based_on_atom_types[row.nsproj_fpath] = {}\n",
    "        for symbol in chemical_symbols[1::]:\n",
    "            voting_based_on_atom_types[row.nsproj_fpath][symbol] = 0\n",
    "        if isinstance(row.dirty_atom_types, str):\n",
    "            for symbol in [\n",
    "                x.strip()\n",
    "                for x in row.dirty_atom_types.replace(\"?\", \"\").split(\",\")\n",
    "                if x.strip()\n",
    "            ]:\n",
    "                voting_based_on_atom_types[row.nsproj_fpath][symbol] = 1\n",
    "# print(voting_based_on_user_name)\n",
    "# print(voting_based_on_atom_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48c64e-4ec8-4da0-a45a-d46febd21e98",
   "metadata": {},
   "source": [
    "### Evaluate the voting results to identify which projects to use for the Dec, 11th talk of Christoph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf5b04cb-d1e1-498e-b29b-7b7aae685728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../nion_data/Haas/2020-07-28_HZO_2172/2020-07-28_HZO_2172.nsproj\n",
      "../../nion_data/Haas/2021-09-16_SmTe3_T3/2021-09-16_SmTe3_T3.nsproj\n",
      "../../nion_data/Wargulski/2022_12_21_CsPbIBr3_largeNPs_EELS_2ndTry/2022_12_21_CsPbIBr3_largeNPs_EELS_2ndTry.nsproj\n",
      "../../nion_data/AEljarrat/2021_Au-NRs_Yuhang/20210812 Au-NRs bare.nsproj\n",
      "../../nion_data/Haas/2021-01-25_Graphite_pumping/2021-01-25_Graphite_pumping.nsproj\n",
      "../../nion_data/Haas/2021-04-16_AlScN_2nd/2021-04-16_AlScN_2nd.nsproj\n",
      "../../nion_data/AEljarrat/BaSnO3 IKZ/20201208 PV01.nsproj\n",
      "../../nion_data/Haas/2020-10-22_Sn-InN_5A/2020-10-22_Sn-InN_5A.nsproj\n",
      "../../nion_data/Haas/2022-03-24_NbS3_D1_60kV/2022-03-24_NbS3_D1_60kV.nsproj\n",
      "../../nion_data/Fairman/FeCr2O4_LARBED_13_11_23/FeCr2O4_LARBED_13_11_23.nsproj\n",
      "../../nion_data/Haas/2025-02-10_N4071_GaN-NWs_60kV/2025-02-10_N4071_GaN-NWs_60kV.nsproj\n",
      "../../nion_data/March/2021-11-22_Juri_Si_110/2021-11-22_Juri_Si_110.nsproj\n",
      "../../nion_data/Haas/2023-09-26_CuS_nano-platelets_60kV/2023-09-26_CuS_nano-platelets_60kV.nsproj\n",
      "../../nion_data/Nerl/25-01-14_G-hBN-G_12643posE5/25-01-14_G-hBN-G_12643posE5.nsproj\n",
      "../../nion_data/Haas/2020-10-16_MoS2-Kor/2020-10-16_MoS2-Kor.nsproj\n",
      "../../nion_data/AEljarrat/BaSnO3 IKZ/20210127 PV01 - after plasma clean.nsproj\n",
      "../../nion_data/Haas/2021-04-19_Diamond_110/2021-04-19_Diamond_110.nsproj\n",
      "../../nion_data/Haas/2024-05-28_amorphous_ice_mom-res_EELS/2024-05-28_amorphous_ice_mom-res_EELS.nsproj\n",
      "../../nion_data/Haas/2020-07-06_NbH-T10_GaAs-NWs/2020-07-06_NbH-T10_GaAs-NWs.nsproj\n",
      "../../nion_data/AEljarrat/2021_STO_Amari/20211026 STO session 2.nsproj\n",
      "../../nion_data/Haas/2024-04-08_GaN_NWs_N3757_holey_C_new_60kV/2024-04-08_GaN_NWs_N3757_holey_C_new_60kV.nsproj\n",
      "../../nion_data/AEljarrat/2020 c-Si/20200928 c-Si 60kV.nsproj\n",
      "../../nion_data/AEljarrat/2021_STO_Amari/20201109_AB_STO_86_Amari_1.nsproj\n",
      "../../nion_data/Haas/2021-10-01_Fe_Sigma5_GB/2021-10-01_Fe_Sigma5_GB.nsproj\n",
      "../../nion_data/Pekin/Pekin/2020_07_20_zeolite_60kv/2020_07_20_zeolite_60kv.nsproj\n",
      "../../nion_data/Elgvin/20240124-het-posA-box33-MoS2-WSe2.nsproj\n",
      "../../nion_data/AEljarrat/2020 CIGSe PVComB/CIGSe_PVcomB.nsproj\n",
      "../../nion_data/Haas/2024-10-10_N4071_GaN_NW_60kV/2024-10-10_N4071_GaN_NW_60kV.nsproj\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# voting results analyzed for sampling one representative of each nxdata type from each colleagues\n",
    "def get_byte_size(nsproj_fpath):\n",
    "    byte_size = 0\n",
    "    for row in nsprojects.itertuples(index=True):\n",
    "        if nsproj_fpath != row.nsproj_fpath:\n",
    "            continue\n",
    "        else:\n",
    "            byte_size = row.total_size_bytes\n",
    "            break\n",
    "    return byte_size\n",
    "\n",
    "\n",
    "def byte_to_gib(byte_size: int) -> str:\n",
    "    return f\"{np.around((byte_size / (1024**3)), decimals=3)} GiB\"\n",
    "\n",
    "\n",
    "nsproj_fpath_selection: str = set()\n",
    "for nxdata_type in nxdata_types:\n",
    "    # pick one representative the entry with the most diverse atom_types\n",
    "    # search until one representative found\n",
    "    # potential: list[tuple[str, int]] = []\n",
    "    for nsproj_fpath, dict_with_votes in voting_based_on_expected_nxdata.items():\n",
    "        # filter out\n",
    "        if dict_with_votes[nxdata_type] == 0:\n",
    "            continue\n",
    "        if nsproj_fpath in nsproj_fpath_selection:\n",
    "            continue\n",
    "        total_atom_types = 0\n",
    "        for key, vote in voting_based_on_atom_types[nsproj_fpath].items():\n",
    "            total_atom_types += vote\n",
    "        if total_atom_types == 0:\n",
    "            del total_atom_types\n",
    "            continue\n",
    "        # potential.append((nsproj_fpath, get_byte_size(nsproj_fpath)))\n",
    "        # continue\n",
    "        if get_byte_size(nsproj_fpath) > (8 * (1024**3)):\n",
    "            continue\n",
    "        # jsut pick the first one\n",
    "        nsproj_fpath_selection.add(nsproj_fpath)\n",
    "        print(\n",
    "            f\"{nsproj_fpath}\"\n",
    "        )  # , {byte_to_gib(get_byte_size(nsproj_fpath))}, {nxdata_type}\")\n",
    "        del total_atom_types\n",
    "        break\n",
    "    # potential.sort(key=lambda x: x[1])  # modifies the original list\n",
    "    # if len(potential) > 0:\n",
    "    #     print(f\"{nxdata_type}, {byte_to_gib(potential[0][1])}\")\n",
    "print(len(nsproj_fpath_selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e6c01-2719-4218-83c9-c6033e96d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Voting which datasets to take"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
