{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e2bd0-2ff4-424c-9512-a5cc60bf320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynxtools_em.configurations.image_png_protochips_cfg as protochips\n",
    "import pynxtools_em.configurations.image_tiff_hitachi_cfg as hitachi\n",
    "import pynxtools_em.configurations.image_tiff_jeol_cfg as jeol\n",
    "import pynxtools_em.configurations.image_tiff_point_electronic_cfg as point\n",
    "import pynxtools_em.configurations.image_tiff_tescan_cfg as tescan\n",
    "import pynxtools_em.configurations.image_tiff_tfs_cfg as thermofisher\n",
    "import pynxtools_em.configurations.image_tiff_zeiss_cfg as zeiss\n",
    "import pynxtools_em.configurations.nion_cfg as nion\n",
    "import pynxtools_em.configurations.rsciio_gatan_cfg as gatan\n",
    "import pynxtools_em.configurations.rsciio_velox_cfg as velox\n",
    "\n",
    "from pynxtools_em.concepts.mapping_functors_pint import get_case\n",
    "techpartners = {\"AXON\": protochips,\n",
    "                \"HITACHI\": hitachi,\n",
    "                \"JEOL\": jeol,\n",
    "                \"DISS\": point,\n",
    "                \"TESCAN\": tescan,\n",
    "                \"TFS\": thermofisher,\n",
    "                \"ZEISS\": zeiss,\n",
    "                \"NION\": nion,\n",
    "                \"GATAN\": gatan,\n",
    "                \"VELOX\": velox}\n",
    "headers = {\"AXON\": \"# AXON Protochips Portable Network Graphics PNG\",\n",
    "           \"HITACHI\": \"# Hitachi Tagged Image File Format TIFF\",\n",
    "           \"JEOL\": \"# JEOL Tagged Image File Format TIFF\",\n",
    "           \"DISS\": \"# point electronic DISS Tagged Image Format TIFF\",\n",
    "           \"TESCAN\": \"# TESCAN Tagged Image File Format TIFF\",\n",
    "           \"TFS\": \"# ThermoFisher Tagged Image File Format TIFF\",\n",
    "           \"ZEISS\": \"# Zeiss Tagged Image File Format TIFF\",\n",
    "           \"NION\": \"# Nion Co. projects with NDATA and HDF5 files\",\n",
    "           \"GATAN\": \"# Gatan DigitalMicrograph DM3/DM4\",\n",
    "           \"VELOX\": \"# ThermoFisher Velox EMD\"}\n",
    "\n",
    "mdfiles = {\"AXON\": \"zip_png_axon.md\",\n",
    "           \"HITACHI\": \"tiff_hitachi.md\",\n",
    "           \"JEOL\": \"tiff_jeol.md\",\n",
    "           \"DISS\": \"tiff_point.md\",\n",
    "           \"TESCAN\": \"tiff_tescan.md\",\n",
    "           \"TFS\": \"tiff_tfs.md\",\n",
    "           \"ZEISS\": \"tiff_zeiss.md\",\n",
    "           \"NION\": \"nxs_nion.md\",\n",
    "           \"GATAN\": \"rsciio_gatan.md\",\n",
    "           \"VELOX\": \"rsciio_velox.md\"}\n",
    "    \n",
    "for techpartner, cfg in techpartners.items():\n",
    "    print(f\"{techpartner} >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    src_concepts = set()\n",
    "    verbose = False\n",
    "    for key, obj in vars(cfg).items():\n",
    "        if key.startswith(f\"{techpartner}_\") and not key.endswith((\"_WHICH_IMAGE\", \"_WHICH_SPECTRUM\", \"_CONCEPT_PREFIXES\")):\n",
    "            if verbose:\n",
    "                print(key)\n",
    "            prefix_src = []\n",
    "            concepts = []\n",
    "            # print(obj)\n",
    "            for k, v in obj.items():\n",
    "                if not k.startswith(\"prefix\"):\n",
    "                    if k != \"use\":\n",
    "                        if isinstance(v, list):\n",
    "                            for entry in v:\n",
    "                                case = get_case(entry)\n",
    "                                if verbose:\n",
    "                                    print(f\"{entry} >>>> {case}\")\n",
    "                                if case == \"case_one\":\n",
    "                                    concepts.append(entry)\n",
    "                                elif case == \"case_two_str\":     \n",
    "                                    concepts.append(entry[1])\n",
    "                                elif case == \"case_two_list\":\n",
    "                                    for val in entry[1]:\n",
    "                                        concepts.append(val)\n",
    "                                elif case == \"case_three_str\":\n",
    "                                    concepts.append(entry[2])\n",
    "                                elif case == \"case_three_list\":\n",
    "                                    for val in entry[2]:\n",
    "                                        concepts.append(val)\n",
    "                                # TODO::add remaining cases\n",
    "                                elif case == \"case_five_str\":\n",
    "                                    concepts.append(entry[2])\n",
    "                                elif case == \"case_five_list\":\n",
    "                                    for val in entry[2]:\n",
    "                                        concepts.append(val)\n",
    "                                elif case == \"case_six\":\n",
    "                                    concepts.append(entry[2])\n",
    "                                    concepts.append(entry[3])\n",
    "                elif k == \"prefix_src\":\n",
    "                    if isinstance(v, str):\n",
    "                        prefix_src.append(v)\n",
    "                    elif isinstance(v, list):\n",
    "                        for val in v:\n",
    "                            prefix_src.append(val)\n",
    "            for prefix in prefix_src:\n",
    "                for concept in concepts:\n",
    "                    src_concepts.add(f\"{prefix}{concept}\")\n",
    "    \n",
    "    print(f\"{techpartner} >>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    txt = []\n",
    "    txt.append(f\"{headers[techpartner]}\")\n",
    "    txt.append(\"\")\n",
    "    txt.append(\"The pynxtools-em parser and normalizer reads the following content and maps them on respective NeXus concepts that are defined in the NXem application definition:\")\n",
    "    txt.append(\"\")\n",
    "    txt.append(\"| Concept | NeXus/HDF5 |\")\n",
    "    txt.append(\"| --------------- | --------------  |\")\n",
    "    for src_concept in sorted(src_concepts):\n",
    "        txt.append(f\"| {src_concept} | :heavy_check_mark: |\")\n",
    "\n",
    "    txt.append(\"\")\n",
    "    fp = open(mdfiles[techpartner], \"w\")\n",
    "    fp.write(\"\\n\".join(txt))\n",
    "    fp.close()\n",
    "    del txt\n",
    "            # print(obj)\n",
    "            # get case\n",
    "            # fish all src concepts to build sorted list of {prefix_src}/src for all {prefix_src}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753eec4-0bea-4e39-80c6-520f5e00bd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0962859-5aef-49d8-8832-f9fb7a30921e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
